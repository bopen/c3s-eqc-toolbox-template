{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pooch\n",
    "import tqdm\n",
    "import xarray as xr\n",
    "from c3s_eqc_automatic_quality_control import diagnostics, download\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of wind data-files\n",
    "col_dict = {\n",
    "    \"SOUID\": (0, 6),\n",
    "    \"SOUNAME\": (7, 47),\n",
    "    \"CN\": (48, 50),\n",
    "    \"LAT\": (51, 60),\n",
    "    \"LON\": (61, 71),\n",
    "    \"HGHT\": (72, 76),\n",
    "    \"ELEID\": (77, 81),\n",
    "    \"START\": (82, 90),\n",
    "    \"STOP\": (91, 99),\n",
    "    \"PARID\": (100, 105),\n",
    "    \"PARNAME\": (106, 156),\n",
    "}\n",
    "\n",
    "# Threshold for maximum allowed NaNs\n",
    "max_nans = 365 * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Define data request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time\n",
    "start = \"1985-01-01\"\n",
    "stop = \"2020-12-31\"\n",
    "\n",
    "# CERRA\n",
    "cerra_id = \"reanalysis-cerra-single-levels\"\n",
    "cerra_request = {\n",
    "    \"product_type\": \"analysis\",\n",
    "    \"data_type\": \"reanalysis\",\n",
    "    \"level_type\": \"surface_or_atmosphere\",\n",
    "    \"variable\": [\"10m_wind_speed\"],\n",
    "    \"time\": [\"00:00\", \"06:00\", \"12:00\", \"18:00\"],\n",
    "    \"data_format\": \"grib\",\n",
    "}\n",
    "\n",
    "# ERA5\n",
    "era5_id = \"reanalysis-era5-single-levels-timeseries\"\n",
    "era5_request = {\n",
    "    \"variable\": [\"10m_u_component_of_wind\", \"10m_v_component_of_wind\"],\n",
    "    \"date\": [f\"{start}/{stop}\"],\n",
    "    \"data_format\": \"netcdf\",\n",
    "}\n",
    "\n",
    "# ECA European Climate Assessment & Dataset\n",
    "eca_url = \"https://knmi-ecad-assets-prd.s3.amazonaws.com/download/ECA_nonblend_fg.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Define functions to cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dms_to_decimal(dms_str):\n",
    "    \"\"\"\n",
    "    Convert a DMS (degrees:minutes:seconds) string to decimal degrees.\n",
    "\n",
    "    Example input: '+54:19:32' -> 54.32555556\n",
    "    \"\"\"\n",
    "    sign = -1 if dms_str.startswith(\"-\") else 1\n",
    "    dms_str = dms_str.strip(\"+-\")  # Remove sign for splitting\n",
    "    degrees, minutes, seconds = map(float, dms_str.split(\":\"))\n",
    "    return sign * (degrees + minutes / 60 + seconds / 3600)\n",
    "\n",
    "\n",
    "def extract_daily_stations(ds, grid_out, **xesmf_kwargs):\n",
    "    (da,) = ds.data_vars.values()\n",
    "    da = diagnostics.regrid(da, grid_out, **xesmf_kwargs)\n",
    "    da = da.resample(forecast_reference_time=\"1D\").mean()\n",
    "    da = da.chunk(forecast_reference_time=-1, station=1)\n",
    "    da.encoding[\"chunksizes\"] = tuple(map(max, da.chunks))\n",
    "    return da.to_dataset()\n",
    "\n",
    "\n",
    "def compute_wind_speed(ds):\n",
    "    da = np.hypot(ds[\"u10\"], ds[\"v10\"]).resample(time=\"1D\").mean()\n",
    "    da.attrs = {\"long_name\": \"10 metre wind speed\", \"units\": ds[\"u10\"].units}\n",
    "    return da.to_dataset(name=\"wind_speed\")\n",
    "\n",
    "\n",
    "def compare_statistic_scatter(\n",
    "    da, reference, target, stat=\"mean\", top_n_outliers=4, ax=None, season=None\n",
    "):\n",
    "    season_months = {\n",
    "        \"DJF\": [12, 1, 2],\n",
    "        \"MAM\": [3, 4, 5],\n",
    "        \"JJA\": [6, 7, 8],\n",
    "        \"JAS\": [7, 8, 9],\n",
    "        \"SON\": [9, 10, 11],\n",
    "        \"OND\": [10, 11, 12],\n",
    "    }\n",
    "    # Apply month and positivity filter\n",
    "    da = da.where(da > 0)\n",
    "    if season is not None:\n",
    "        da = da.where(da[\"time\"].dt.month.isin(season_months[season]))\n",
    "    da = getattr(da, stat)(\"time\")\n",
    "    da_reference = da.sel(product=reference)\n",
    "    da_target = da.sel(product=target)\n",
    "\n",
    "    # Perform linear regression: fit y = m*x + b\n",
    "    slope, intercept = np.polyfit(da_reference, da_target, 1)\n",
    "    fit_line = slope * da_reference + intercept\n",
    "\n",
    "    # Compute R^2\n",
    "    res = np.sum((da_target - fit_line) ** 2)\n",
    "    tot = np.sum((da_target - np.mean(da_target)) ** 2)\n",
    "    r_squared = 1 - res / tot\n",
    "\n",
    "    # Compute residuals and find 4 largest outliers\n",
    "    residuals = np.abs(da_target - fit_line)\n",
    "    outlier_indices = np.argsort(residuals)[-top_n_outliers:]  # n largest residuals\n",
    "\n",
    "    # Create plot\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "        # Create scatter plot\n",
    "    ax.scatter(da_reference, da_target, color=\"blue\", alpha=0.7)\n",
    "    min_val = min(da_target.min().item(), da_reference.min().item())\n",
    "    max_val = max(da_target.max().item(), da_reference.max().item())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], \"k-\", label=\"_\")\n",
    "    ax.plot(\n",
    "        da_reference,\n",
    "        fit_line,\n",
    "        \"r-\",\n",
    "        label=f\"Linear fit: y = {slope:.2f}x + {intercept:.2f} (RÂ² = {r_squared:.2f})\",\n",
    "    )\n",
    "\n",
    "    # Annotate outliers\n",
    "    for i in outlier_indices:\n",
    "        ax.annotate(\n",
    "            str(da[\"SOUNAME\"][i].values),\n",
    "            (da_reference[i], da_target[i]),\n",
    "            textcoords=\"offset points\",\n",
    "            xytext=(5, 5),\n",
    "            ha=\"left\",\n",
    "            fontsize=9,\n",
    "            color=\"darkred\",\n",
    "        )\n",
    "\n",
    "    # Plot labels and title\n",
    "    ax.set_xlim(min_val, max_val)\n",
    "    ax.set_ylim(min_val, max_val)\n",
    "    ax.set_xlabel(f\"{reference} [m/s]\")\n",
    "    ax.set_ylabel(f\"{target} [m/s]\")\n",
    "    ax.set_title(f\"{season}\")\n",
    "    ax.grid(True)\n",
    "    ax.legend(fontsize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Import and filter weather station data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = pooch.retrieve(url=eca_url, known_hash=None, processor=pooch.Unzip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Extract metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metadata in df_sources\n",
    "(fname,) = [fname for fname in fnames if \"sources\" in fname]\n",
    "df_sources = pd.read_fwf(\n",
    "    fname,\n",
    "    colspecs=list(col_dict.values()),\n",
    "    skiprows=24,\n",
    "    names=list(col_dict),\n",
    ")\n",
    "\n",
    "# Convert LAT and LON to decimal degrees\n",
    "for col in [\"LAT\", \"LON\"]:\n",
    "    df_sources[col] = df_sources[col].apply(dms_to_decimal)\n",
    "\n",
    "# Convert START and STOP to datetime\n",
    "for col in [\"START\", \"STOP\"]:\n",
    "    df_sources[col] = pd.to_datetime(df_sources[col], format=\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Filter best quality (FG1, FG2) and check data availability by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filter for FG1 and FG2\n",
    "df_plot = df_sources[df_sources[\"ELEID\"].isin([\"FG1\", \"FG2\"])]\n",
    "\n",
    "# 2. Group by CN and SOURCE to count entries\n",
    "# Turns ELEID into columns: FG1, FG2\n",
    "df_plot = df_plot.groupby([\"CN\", \"ELEID\"]).size().unstack(fill_value=0)\n",
    "\n",
    "# 3. Add total count and sort by it\n",
    "df_plot[\"Total\"] = df_plot.sum(axis=1)\n",
    "df_plot = df_plot.sort_values(by=\"Total\", ascending=False).drop(columns=\"Total\")\n",
    "\n",
    "# 4. Plotting\n",
    "df_plot.plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=False,\n",
    "    color={\"FG1\": \"cornflowerblue\", \"FG2\": \"lightcoral\"},\n",
    "    figsize=(12, 6),\n",
    ")\n",
    "\n",
    "# 5. Customize the plot\n",
    "plt.title(\"Number of FG1 and FG2 ELEID per Country\", fontsize=16)\n",
    "plt.xlabel(\"Country\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title=\"ELEID\")\n",
    "plt.tight_layout()\n",
    "\n",
    "del df_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Import daily weather station data for target country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data for Norway, with the largest number of FG2 quality data\n",
    "country_code = \"NO\"\n",
    "country_stations_meta = df_sources[df_sources[\"CN\"] == country_code]\n",
    "\n",
    "# Ensure the source id's SOUID values are strings (in case some are not)\n",
    "country_stations_id = country_stations_meta[\"SOUID\"].astype(str).tolist()\n",
    "\n",
    "# Filter filenames that contain any of the SOUID string in the selected stations\n",
    "country_fnames = [\n",
    "    fname\n",
    "    for fname in fnames\n",
    "    if any(f\"SOUID{id_}\" in fname for id_ in country_stations_id)\n",
    "]\n",
    "\n",
    "# Read the data. Each array has attrbutes from the corresponding row of the dataframe country_stations\n",
    "# (this may be improved with more efficient coding)\n",
    "dataarrays = []\n",
    "for fname in tqdm.tqdm(country_fnames):\n",
    "    # Read CSV into a DataFrame\n",
    "    df = pd.read_csv(fname, skipinitialspace=True, skiprows=18)\n",
    "\n",
    "    # Convert DATE to datetime format\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"], format=\"%Y%m%d\")\n",
    "\n",
    "    # Filter out missing values\n",
    "    df = df[df[\"FG\"] != -9999]\n",
    "\n",
    "    # Optionally use SOUID or STAID as the label if available\n",
    "    souid = df[\"SOUID\"].iloc[0]\n",
    "\n",
    "    # Extract metadata for the current stattion\n",
    "    meta = country_stations_meta[country_stations_meta[\"SOUID\"] == souid].iloc[0]\n",
    "\n",
    "    # Convert to DataArray\n",
    "    da = xr.DataArray(\n",
    "        data=df[\"FG\"].values,\n",
    "        coords={\"time\": df[\"DATE\"].values},\n",
    "        dims=[\"time\"],\n",
    "        name=\"FG\",\n",
    "    )\n",
    "    da = da.expand_dims(station=[str(souid)])\n",
    "    da = da.assign_coords({k: (\"station\", [v]) for k, v in meta.items()})\n",
    "    dataarrays.append(da)\n",
    "\n",
    "obs = xr.concat(dataarrays, \"station\").sel(time=slice(start, stop))\n",
    "obs[\"LON\"].attrs[\"standard_name\"] = \"longitude\"\n",
    "obs[\"LAT\"].attrs[\"standard_name\"] = \"latitude\"\n",
    "grid_out = obs.to_dataset().drop_dims(\"time\")[[\"LAT\", \"LON\"]]\n",
    "del dataarrays, df_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Filter weather stations with sufficient amount of available records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = obs.where(obs.isnull().sum(\"time\") < max_nans, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Plot available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "cmap = ListedColormap(\n",
    "    [\n",
    "        (1, 0, 0, 0),  # Transparent for NaN    (0)\n",
    "        (1, 0, 0, 1),  # Red for available data (1)\n",
    "    ]\n",
    ")\n",
    "plt.figure(figsize=(15, obs.sizes[\"station\"] * 0.3))\n",
    "plt.imshow(\n",
    "    obs.notnull().squeeze(),\n",
    "    aspect=\"auto\",\n",
    "    interpolation=\"none\",\n",
    "    extent=[*obs[\"time\"].values[[0, -1]], 0, obs.sizes[\"station\"]],\n",
    "    cmap=cmap,\n",
    ")\n",
    "\n",
    "# Ticks and labels\n",
    "plt.yticks(np.arange(obs.sizes[\"station\"]) + 0.5, obs[\"SOUNAME\"].values)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Station\")\n",
    "plt.title(\"Data Availability Over Time by Station\")\n",
    "plt.colorbar(label=\"Data Present (1=Yes, 0=No)\", ticks=[0, 1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# Map weather stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract station metadata\n",
    "lats = obs[\"LAT\"].values  # latitude  (shape: n_stations,)\n",
    "lons = obs[\"LON\"].values  # longitude\n",
    "names = obs[\"SOUNAME\"].values  # station names\n",
    "\n",
    "# Define the Lambert-Conformal projection\n",
    "proj = ccrs.LambertConformal(\n",
    "    central_longitude=15,  # roughly the middle of Norway\n",
    "    central_latitude=67,  # latitude of balance\n",
    "    standard_parallels=(60, 80),  # secant cone cuts; tweak if needed\n",
    ")\n",
    "\n",
    "# Build the map\n",
    "fig = plt.figure(figsize=(8, 10))\n",
    "ax = plt.axes(projection=proj)\n",
    "\n",
    "# Focus on mainland and northern Norway\n",
    "ax.set_extent([-5, 33, 57, 80], crs=ccrs.PlateCarree())\n",
    "\n",
    "ax.add_feature(cfeature.LAND, facecolor=\"#f0f0f0\")\n",
    "ax.add_feature(cfeature.COASTLINE, linewidth=0.6)\n",
    "ax.add_feature(cfeature.BORDERS, linewidth=0.5)\n",
    "ax.gridlines(draw_labels=True, linewidth=0.25, linestyle=\"--\")\n",
    "\n",
    "# Plot the station locations\n",
    "ax.scatter(\n",
    "    lons,\n",
    "    lats,\n",
    "    s=25,\n",
    "    color=\"darkred\",\n",
    "    edgecolors=\"k\",\n",
    "    zorder=3,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "# Annotate each station\n",
    "# for lon, lat, name in zip(lons, lats, names):\n",
    "#    ax.text(\n",
    "#        lon + 0.25, lat + 0.15, name,\n",
    "#        fontsize=6, transform=ccrs.PlateCarree(), zorder=4\n",
    "#    )\n",
    "\n",
    "ax.set_title(\"Weather Stations with quality wind data in Norway\", pad=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "# Import CERRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CERRA at the nearest grid points to se\n",
    "request = download.update_request_date(cerra_request, start, stop, stringify_dates=True)\n",
    "ds = download.download_and_transform(\n",
    "    cerra_id,\n",
    "    request,\n",
    "    transform_func=extract_daily_stations,\n",
    "    transform_func_kwargs={\n",
    "        \"grid_out\": grid_out,\n",
    "        \"method\": \"nearest_s2d\",\n",
    "        \"locstream_out\": True,\n",
    "    },\n",
    "    chunks={\"year\": 1, \"month\": 1},\n",
    "    drop_variables=[\"step\"],\n",
    "    cached_open_mfdataset_kwargs={\n",
    "        \"concat_dim\": \"forecast_reference_time\",\n",
    "        \"combine\": \"nested\",\n",
    "        \"data_vars\": \"minimal\",\n",
    "        \"coords\": \"minimal\",\n",
    "        \"compat\": \"override\",\n",
    "    },\n",
    ")\n",
    "(cerra,) = ds.sel(station=obs[\"station\"]).data_vars.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "# Import ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for station, da_station in tqdm.tqdm(obs[\"station\"].groupby(\"station\")):\n",
    "    ds = download.download_and_transform(\n",
    "        era5_id,\n",
    "        era5_request\n",
    "        | {\n",
    "            \"location\": {\n",
    "                \"longitude\": da_station[\"LON\"].item(),\n",
    "                \"latitude\": da_station[\"LAT\"].item(),\n",
    "            }\n",
    "        },\n",
    "        transform_func=compute_wind_speed,\n",
    "        quiet=True,\n",
    "    )\n",
    "    datasets.append(ds.expand_dims(station=[station]))\n",
    "(era5,) = xr.concat(datasets, \"station\").data_vars.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Combine dataarrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = xr.concat(\n",
    "    [\n",
    "        cerra.expand_dims(product=[\"CERRA\"]).rename(forecast_reference_time=\"time\"),\n",
    "        obs.expand_dims(product=[\"OBS\"]).rename(cerra.name) / 10,\n",
    "        era5.expand_dims(product=[\"ERA5\"]),\n",
    "    ],\n",
    "    \"product\",\n",
    ")\n",
    "da[\"time\"].attrs = {\"long_name\": \"time\"}\n",
    "da = da.compute()\n",
    "del cerra, era5, obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Plot statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of statistics to compare\n",
    "statistics = [\"mean\", \"var\", \"min\", \"max\"]\n",
    "seasons = [\"DJF\", \"MAM\", \"JJA\", \"SON\"]\n",
    "targets = [\"CERRA\", \"ERA5\"]\n",
    "\n",
    "for target in targets:\n",
    "    for j, stat in enumerate(statistics):\n",
    "        # Create subplots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        # Plot each statistic in a subplot\n",
    "        for i, season in enumerate(seasons):\n",
    "            compare_statistic_scatter(\n",
    "                da,\n",
    "                \"OBS\",\n",
    "                target,\n",
    "                stat=stat,\n",
    "                top_n_outliers=2,\n",
    "                ax=axes[i],\n",
    "                season=season,\n",
    "            )\n",
    "\n",
    "        plt.suptitle(\n",
    "            f\"{target} vs OBS  {stat.capitalize()} Wind Speed Statistics\", fontsize=16\n",
    "        )\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
