{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pooch\n",
    "import tqdm\n",
    "import xarray as xr\n",
    "from c3s_eqc_automatic_quality_control import diagnostics, download\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of wind data-files\n",
    "col_dict = {\n",
    "    \"SOUID\": (0, 6),\n",
    "    \"SOUNAME\": (7, 47),\n",
    "    \"CN\": (48, 50),\n",
    "    \"LAT\": (51, 60),\n",
    "    \"LON\": (61, 71),\n",
    "    \"HGHT\": (72, 76),\n",
    "    \"ELEID\": (77, 81),\n",
    "    \"START\": (82, 90),\n",
    "    \"STOP\": (91, 99),\n",
    "    \"PARID\": (100, 105),\n",
    "    \"PARNAME\": (106, 156),\n",
    "}\n",
    "\n",
    "# Threshold for maximum allowed NaNs\n",
    "max_nans = 365 * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Define data request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time\n",
    "start = \"1985-01-01\"\n",
    "stop = \"2020-12-31\"\n",
    "\n",
    "# CERRA\n",
    "cerra_id = \"reanalysis-cerra-single-levels\"\n",
    "cerra_request = {\n",
    "    \"product_type\": \"analysis\",\n",
    "    \"data_type\": \"reanalysis\",\n",
    "    \"level_type\": \"surface_or_atmosphere\",\n",
    "    \"variable\": [\"10m_wind_speed\"],\n",
    "    \"time\": [\"00:00\", \"06:00\", \"12:00\", \"18:00\"],\n",
    "    \"data_format\": \"grib\",\n",
    "}\n",
    "\n",
    "# ERA5\n",
    "era5_id = \"reanalysis-era5-single-levels-timeseries\"\n",
    "era5_request = {\n",
    "    \"variable\": [\"10m_u_component_of_wind\", \"10m_v_component_of_wind\"],\n",
    "    \"date\": [f\"{start}/{stop}\"],\n",
    "    \"data_format\": \"netcdf\",\n",
    "}\n",
    "\n",
    "# ECA European Climate Assessment & Dataset\n",
    "eca_url = \"https://knmi-ecad-assets-prd.s3.amazonaws.com/download/ECA_nonblend_fg.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Define functions to cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dms_to_decimal(dms_str):\n",
    "    \"\"\"\n",
    "    Convert a DMS (degrees:minutes:seconds) string to decimal degrees.\n",
    "\n",
    "    Example input: '+54:19:32' -> 54.32555556\n",
    "    \"\"\"\n",
    "    sign = -1 if dms_str.startswith(\"-\") else 1\n",
    "    dms_str = dms_str.strip(\"+-\")  # Remove sign for splitting\n",
    "    degrees, minutes, seconds = map(float, dms_str.split(\":\"))\n",
    "    return sign * (degrees + minutes / 60 + seconds / 3600)\n",
    "\n",
    "\n",
    "def extract_daily_stations(ds, grid_out, **xesmf_kwargs):\n",
    "    (da,) = ds.data_vars.values()\n",
    "    da = diagnostics.regrid(da, grid_out, **xesmf_kwargs)\n",
    "    da = da.resample(forecast_reference_time=\"1D\").mean()\n",
    "    da = da.chunk(forecast_reference_time=-1, station=1)\n",
    "    da.encoding[\"chunksizes\"] = tuple(map(max, da.chunks))\n",
    "    return da.to_dataset()\n",
    "\n",
    "\n",
    "def compute_wind_speed(ds):\n",
    "    da = np.hypot(ds[\"u10\"], ds[\"v10\"]).resample(time=\"1D\").mean()\n",
    "    da.attrs = {\"long_name\": \"10 metre wind speed\", \"units\": ds[\"u10\"].units}\n",
    "    return da.to_dataset(name=\"wind_speed\")\n",
    "\n",
    "\n",
    "def model_fit(da_reference, da_target, alpha=0.05):\n",
    "    # stats.linregress gives you the slope, intercept, and the standard error of the slope in one call.\n",
    "    # The critical-t multiplier converts standard errors into two-sided 95% intervals\n",
    "    # (df = n–2 for simple linear regression).\n",
    "    # The intercept standard error depends on the spread of the x values,\n",
    "    # so we compute it explicitly from the residual variance\n",
    "\n",
    "    # Fit the model  y = m·x + b\n",
    "    slope, intercept, r_value, p_value, slope_std_err = stats.linregress(\n",
    "        da_reference, da_target\n",
    "    )\n",
    "\n",
    "    # 1-alpha % confidence limits\n",
    "    alpha = 0.05\n",
    "    n = da_reference.size\n",
    "    df = n - 2  # degrees of freedom\n",
    "    t_crit = stats.t.ppf(1 - alpha / 2, df)  # two-sided critical t value\n",
    "\n",
    "    slope_ci = (slope - t_crit * slope_std_err, slope + t_crit * slope_std_err)\n",
    "\n",
    "    y_hat = slope * da_reference + intercept\n",
    "    resid = da_target - y_hat\n",
    "    sse = np.sum(resid**2)\n",
    "    sigma2 = sse / df\n",
    "    x_bar = da_reference.mean()\n",
    "    Sxx = np.sum((da_reference - x_bar) ** 2)\n",
    "\n",
    "    intercept_std_err = np.sqrt(sigma2 * (1 / n + x_bar**2 / Sxx))\n",
    "    intercept_ci = (\n",
    "        intercept - t_crit * intercept_std_err,\n",
    "        intercept + t_crit * intercept_std_err,\n",
    "    )\n",
    "\n",
    "    return slope, slope_ci, intercept, intercept_ci\n",
    "\n",
    "\n",
    "def compare_statistic_scatter(\n",
    "    da, reference, targets, stat=\"mean\", top_n_outliers=4, ax=None, season=None\n",
    "):\n",
    "    season_months = {\n",
    "        \"DJF\": [12, 1, 2],\n",
    "        \"MAM\": [3, 4, 5],\n",
    "        \"JJA\": [6, 7, 8],\n",
    "        \"JAS\": [7, 8, 9],\n",
    "        \"SON\": [9, 10, 11],\n",
    "        \"OND\": [10, 11, 12],\n",
    "    }\n",
    "    # Apply month and positivity filter\n",
    "    da = da.where(da > 0)\n",
    "    if season is not None:\n",
    "        da = da.where(da[\"time\"].dt.month.isin(season_months[season]))\n",
    "    da = getattr(da, stat)(\"time\")\n",
    "    da_reference = da.sel(product=reference)\n",
    "    for target, colour in targets.items():\n",
    "        da_target = da.sel(product=target)\n",
    "\n",
    "        # Perform linear regression: fit y = m*x + b\n",
    "        slope, slope_ci, intercept, intercept_ci = model_fit(\n",
    "            da_reference, da_target, alpha=0.05\n",
    "        )\n",
    "        # slope, intercept = np.polyfit(da_reference, da_target, 1)\n",
    "        fit_line = slope * da_reference + intercept\n",
    "\n",
    "        # Compute R^2\n",
    "        res = np.sum((da_target - fit_line) ** 2)\n",
    "        tot = np.sum((da_target - np.mean(da_target)) ** 2)\n",
    "        r_squared = 1 - res / tot\n",
    "\n",
    "        # Compute residuals and find 4 largest outliers\n",
    "        residuals = np.abs(da_target - fit_line)\n",
    "        outlier_indices = np.argsort(residuals)[-top_n_outliers:]  # n largest residuals\n",
    "\n",
    "        # Create plot\n",
    "        if ax is None:\n",
    "            ax = plt.gca()\n",
    "        # Create scatter plot\n",
    "        ax.scatter(da_reference, da_target, color=colour, alpha=0.7)\n",
    "        min_val = min(da_target.min().item(), da_reference.min().item())\n",
    "        max_val = max(da_target.max().item(), da_reference.max().item())\n",
    "        ax.plot([min_val, max_val], [min_val, max_val], \"k-\", label=\"_\")\n",
    "        ax.plot(\n",
    "            da_reference,\n",
    "            fit_line,\n",
    "            f\"{colour}-\",\n",
    "            label=(\n",
    "                f\"{target} \"\n",
    "                f\"m = {[f'{s:.2f}' for s in slope_ci]} \"\n",
    "                f\"b = {[f'{b:.2f}' for b in intercept_ci]} \"\n",
    "                f\"(R² = {r_squared:.2f})\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Annotate outliers\n",
    "        for i in outlier_indices:\n",
    "            ax.annotate(\n",
    "                str(da[\"SOUNAME\"][i].values),\n",
    "                (da_reference[i], da_target[i]),\n",
    "                textcoords=\"offset points\",\n",
    "                xytext=(5, 5),\n",
    "                ha=\"left\",\n",
    "                fontsize=9,\n",
    "                color=\"darkred\",\n",
    "            )\n",
    "\n",
    "    # Plot labels and title\n",
    "    ax.set_xlim(min_val, max_val)\n",
    "    ax.set_ylim(min_val, max_val)\n",
    "    ax.set_xlabel(f\"{reference} [m/s]\")\n",
    "    ax.set_ylabel(\"Reanalysis [m/s]\")\n",
    "    ax.set_title(f\"{season}\")\n",
    "    ax.grid(True)\n",
    "    ax.legend(fontsize=10)"
   ]
  },
  {
   "attachments": {
    "d91e30eb-a75e-4ec7-9c4c-062b2054bd32.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "stats.linregress gives you the slope, intercept, and the standard error of the slope in one call.\n",
    "\n",
    "The critical-t multiplier converts those standard errors into two-sided 95 % intervals (df = n–2 for simple linear regression).\n",
    "\n",
    "The intercept standard error depends on the spread of the x values, so we compute it explicitly from the residual variance\n",
    "\n",
    "![image.png](attachment:d91e30eb-a75e-4ec7-9c4c-062b2054bd32.png)\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Import and filter weather station data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = pooch.retrieve(url=eca_url, known_hash=None, processor=pooch.Unzip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Extract metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metadata in df_sources\n",
    "(fname,) = [fname for fname in fnames if \"sources\" in fname]\n",
    "df_sources = pd.read_fwf(\n",
    "    fname,\n",
    "    colspecs=list(col_dict.values()),\n",
    "    skiprows=24,\n",
    "    names=list(col_dict),\n",
    ")\n",
    "\n",
    "# Convert LAT and LON to decimal degrees\n",
    "for col in [\"LAT\", \"LON\"]:\n",
    "    df_sources[col] = df_sources[col].apply(dms_to_decimal)\n",
    "\n",
    "# Convert START and STOP to datetime\n",
    "for col in [\"START\", \"STOP\"]:\n",
    "    df_sources[col] = pd.to_datetime(df_sources[col], format=\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Filter best quality (FG1, FG2) and check data availability by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filter for FG1 and FG2\n",
    "df_plot = df_sources[df_sources[\"ELEID\"].isin([\"FG1\", \"FG2\"])]\n",
    "\n",
    "# 2. Group by CN and SOURCE to count entries\n",
    "# Turns ELEID into columns: FG1, FG2\n",
    "df_plot = df_plot.groupby([\"CN\", \"ELEID\"]).size().unstack(fill_value=0)\n",
    "\n",
    "# 3. Add total count and sort by it\n",
    "df_plot[\"Total\"] = df_plot.sum(axis=1)\n",
    "df_plot = df_plot.sort_values(by=\"Total\", ascending=False).drop(columns=\"Total\")\n",
    "\n",
    "# 4. Plotting\n",
    "df_plot.plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=False,\n",
    "    color={\"FG1\": \"cornflowerblue\", \"FG2\": \"lightcoral\"},\n",
    "    figsize=(12, 6),\n",
    ")\n",
    "\n",
    "# 5. Customize the plot\n",
    "plt.title(\"Number of FG1 and FG2 ELEID per Country\", fontsize=16)\n",
    "plt.xlabel(\"Country\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title=\"ELEID\")\n",
    "plt.tight_layout()\n",
    "\n",
    "del df_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Import daily weather station data for target country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data for Norway, with the largest number of FG2 quality data\n",
    "country_code = \"NO\"\n",
    "country_stations_meta = df_sources[df_sources[\"CN\"] == country_code]\n",
    "\n",
    "# Ensure the source id's SOUID values are strings (in case some are not)\n",
    "country_stations_id = country_stations_meta[\"SOUID\"].astype(str).tolist()\n",
    "\n",
    "# Filter filenames that contain any of the SOUID string in the selected stations\n",
    "country_fnames = [\n",
    "    fname\n",
    "    for fname in fnames\n",
    "    if any(f\"SOUID{id_}\" in fname for id_ in country_stations_id)\n",
    "]\n",
    "\n",
    "# Read the data. Each array has attrbutes from the corresponding row of the dataframe country_stations\n",
    "# (this may be improved with more efficient coding)\n",
    "dataarrays = []\n",
    "for fname in tqdm.tqdm(country_fnames):\n",
    "    # Read CSV into a DataFrame\n",
    "    df = pd.read_csv(fname, skipinitialspace=True, skiprows=18)\n",
    "\n",
    "    # Convert DATE to datetime format\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"], format=\"%Y%m%d\")\n",
    "\n",
    "    # Filter out missing values\n",
    "    df = df[df[\"FG\"] != -9999]\n",
    "\n",
    "    # Optionally use SOUID or STAID as the label if available\n",
    "    souid = df[\"SOUID\"].iloc[0]\n",
    "\n",
    "    # Extract metadata for the current stattion\n",
    "    meta = country_stations_meta[country_stations_meta[\"SOUID\"] == souid].iloc[0]\n",
    "\n",
    "    # Convert to DataArray\n",
    "    da = xr.DataArray(\n",
    "        data=df[\"FG\"].values,\n",
    "        coords={\"time\": df[\"DATE\"].values},\n",
    "        dims=[\"time\"],\n",
    "        name=\"FG\",\n",
    "    )\n",
    "    da = da.expand_dims(station=[str(souid)])\n",
    "    da = da.assign_coords({k: (\"station\", [v]) for k, v in meta.items()})\n",
    "    dataarrays.append(da)\n",
    "\n",
    "obs = xr.concat(dataarrays, \"station\").sel(time=slice(start, stop))\n",
    "obs[\"LON\"].attrs[\"standard_name\"] = \"longitude\"\n",
    "obs[\"LAT\"].attrs[\"standard_name\"] = \"latitude\"\n",
    "grid_out = obs.to_dataset().drop_dims(\"time\")[[\"LAT\", \"LON\"]]\n",
    "del dataarrays, df_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Filter weather stations with sufficient amount of available records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = obs.where(obs.isnull().sum(\"time\") < max_nans, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Plot available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "cmap = ListedColormap(\n",
    "    [\n",
    "        (1, 0, 0, 0),  # Transparent for NaN    (0)\n",
    "        (1, 0, 0, 1),  # Red for available data (1)\n",
    "    ]\n",
    ")\n",
    "plt.figure(figsize=(15, obs.sizes[\"station\"] * 0.3))\n",
    "plt.imshow(\n",
    "    obs.notnull().squeeze(),\n",
    "    aspect=\"auto\",\n",
    "    interpolation=\"none\",\n",
    "    extent=[*obs[\"time\"].values[[0, -1]], 0, obs.sizes[\"station\"]],\n",
    "    cmap=cmap,\n",
    ")\n",
    "\n",
    "# Ticks and labels\n",
    "plt.yticks(np.arange(obs.sizes[\"station\"]) + 0.5, obs[\"SOUNAME\"].values)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Station\")\n",
    "plt.title(\"Data Availability Over Time by Station\")\n",
    "plt.colorbar(label=\"Data Present (1=Yes, 0=No)\", ticks=[0, 1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# Map weather stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract station metadata\n",
    "lats = obs[\"LAT\"].values  # latitude  (shape: n_stations,)\n",
    "lons = obs[\"LON\"].values  # longitude\n",
    "names = obs[\"SOUNAME\"].values  # station names\n",
    "\n",
    "# Define the Lambert-Conformal projection\n",
    "proj = ccrs.LambertConformal(\n",
    "    central_longitude=15,  # roughly the middle of Norway\n",
    "    central_latitude=67,  # latitude of balance\n",
    "    standard_parallels=(60, 80),  # secant cone cuts; tweak if needed\n",
    ")\n",
    "\n",
    "# Build the map\n",
    "fig = plt.figure(figsize=(8, 10))\n",
    "ax = plt.axes(projection=proj)\n",
    "\n",
    "# Focus on mainland and northern Norway\n",
    "ax.set_extent([-5, 33, 57, 80], crs=ccrs.PlateCarree())\n",
    "\n",
    "ax.add_feature(cfeature.LAND, facecolor=\"#f0f0f0\")\n",
    "ax.add_feature(cfeature.COASTLINE, linewidth=0.6)\n",
    "ax.add_feature(cfeature.BORDERS, linewidth=0.5)\n",
    "ax.gridlines(draw_labels=True, linewidth=0.25, linestyle=\"--\")\n",
    "\n",
    "# Plot the station locations\n",
    "ax.scatter(\n",
    "    lons,\n",
    "    lats,\n",
    "    s=25,\n",
    "    color=\"darkred\",\n",
    "    edgecolors=\"k\",\n",
    "    zorder=3,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "# Annotate each station\n",
    "# for lon, lat, name in zip(lons, lats, names):\n",
    "#    ax.text(\n",
    "#        lon + 0.25, lat + 0.15, name,\n",
    "#        fontsize=6, transform=ccrs.PlateCarree(), zorder=4\n",
    "#    )\n",
    "\n",
    "ax.set_title(\"Weather Stations with quality wind data in Norway\", pad=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "# Import CERRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CERRA at the nearest grid points to se\n",
    "request = download.update_request_date(cerra_request, start, stop, stringify_dates=True)\n",
    "ds = download.download_and_transform(\n",
    "    cerra_id,\n",
    "    request,\n",
    "    transform_func=extract_daily_stations,\n",
    "    transform_func_kwargs={\n",
    "        \"grid_out\": grid_out,\n",
    "        \"method\": \"nearest_s2d\",\n",
    "        \"locstream_out\": True,\n",
    "    },\n",
    "    chunks={\"year\": 1, \"month\": 1},\n",
    "    drop_variables=[\"step\"],\n",
    "    cached_open_mfdataset_kwargs={\n",
    "        \"concat_dim\": \"forecast_reference_time\",\n",
    "        \"combine\": \"nested\",\n",
    "        \"data_vars\": \"minimal\",\n",
    "        \"coords\": \"minimal\",\n",
    "        \"compat\": \"override\",\n",
    "    },\n",
    ")\n",
    "(cerra,) = ds.sel(station=obs[\"station\"]).data_vars.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "# Import ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for station, da_station in tqdm.tqdm(obs[\"station\"].groupby(\"station\")):\n",
    "    ds = download.download_and_transform(\n",
    "        era5_id,\n",
    "        era5_request\n",
    "        | {\n",
    "            \"location\": {\n",
    "                \"longitude\": da_station[\"LON\"].item(),\n",
    "                \"latitude\": da_station[\"LAT\"].item(),\n",
    "            }\n",
    "        },\n",
    "        transform_func=compute_wind_speed,\n",
    "        quiet=True,\n",
    "    )\n",
    "    datasets.append(ds.expand_dims(station=[station]))\n",
    "(era5,) = xr.concat(datasets, \"station\").data_vars.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Combine dataarrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = xr.concat(\n",
    "    [\n",
    "        cerra.expand_dims(product=[\"CERRA\"]).rename(forecast_reference_time=\"time\"),\n",
    "        obs.expand_dims(product=[\"OBS\"]).rename(cerra.name) / 10,\n",
    "        era5.expand_dims(product=[\"ERA5\"]),\n",
    "    ],\n",
    "    \"product\",\n",
    ")\n",
    "da[\"time\"].attrs = {\"long_name\": \"time\"}\n",
    "da = da.compute()\n",
    "del cerra, era5, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of statistics to compare\n",
    "statistics = [\"mean\", \"var\", \"min\", \"max\"]\n",
    "seasons = [\"DJF\", \"MAM\", \"JJA\", \"SON\"]\n",
    "targets = {\"CERRA\": \"r\", \"ERA5\": \"g\"}\n",
    "\n",
    "for j, stat in enumerate(statistics):\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Plot each statistic in a subplot\n",
    "    for i, season in enumerate(seasons):\n",
    "        compare_statistic_scatter(\n",
    "            da,\n",
    "            \"OBS\",\n",
    "            targets,\n",
    "            stat=stat,\n",
    "            top_n_outliers=2,\n",
    "            ax=axes[i],\n",
    "            season=season,\n",
    "        )\n",
    "\n",
    "    plt.suptitle(\n",
    "        f\"Reanalysis vs. observations  {stat.capitalize()} Wind Speed Statistics\",\n",
    "        fontsize=16,\n",
    "    )\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
