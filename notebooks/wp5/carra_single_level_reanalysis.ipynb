{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99c44161",
   "metadata": {},
   "source": [
    "# CARRA Single Level Reanalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6fd3a0",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8ceec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from c3s_eqc_automatic_quality_control import diagnostics, download, plot\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cfc588",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b6a68d-1d37-4af2-8d4e-dbba0b56f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time\n",
    "start = \"1991-01\"\n",
    "stop = \"2020-12\"\n",
    "\n",
    "# Region\n",
    "domain = \"west_domain\"\n",
    "assert domain in (\"east_domain\", \"west_domain\")\n",
    "\n",
    "# Variable\n",
    "variable = \"2m_temperature\"\n",
    "assert variable in (\n",
    "    \"10m_u_component_of_wind\",\n",
    "    \"10m_v_component_of_wind\",\n",
    "    \"10m_wind_direction\",\n",
    "    \"10m_wind_speed\",\n",
    "    \"2m_relative_humidity\",\n",
    "    \"2m_specific_humidity\",\n",
    "    \"2m_temperature\",\n",
    "    \"albedo\",\n",
    "    \"cloud_base\",\n",
    "    \"cloud_top\",\n",
    "    \"fraction_of_snow_cover\",\n",
    "    \"high_cloud_cover\",\n",
    "    \"land_sea_mask\",\n",
    "    \"low_cloud_cover\",\n",
    "    \"mean_sea_level_pressure\",\n",
    "    \"medium_cloud_cover\",\n",
    "    \"orography\",\n",
    "    \"percolation\",\n",
    "    \"sea_ice_area_fraction\",\n",
    "    \"sea_ice_surface_temperature\",\n",
    "    \"sea_surface_temperature\",\n",
    "    \"skin_temperature\",\n",
    "    \"snow_albedo\",\n",
    "    \"snow_density\",\n",
    "    \"snow_depth_water_equivalent\",\n",
    "    \"snow_on_ice_total_depth\",\n",
    "    \"surface_pressure\",\n",
    "    \"surface_roughness\",\n",
    "    \"surface_roughness_length_for_heat\",\n",
    "    \"surface_runoff\",\n",
    "    \"total_cloud_cover\",\n",
    "    \"total_column_graupel\",\n",
    "    \"total_column_integrated_water_vapour\",\n",
    "    \"visibility\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c32c19",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced4355c-e8ea-43a7-999a-b7a33f6d54b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = \"reanalysis-carra-single-levels\"\n",
    "request = {\n",
    "    \"domain\": domain,\n",
    "    \"level_type\": \"surface_or_atmosphere\",\n",
    "    \"variable\": variable,\n",
    "    \"product_type\": \"analysis\",\n",
    "    \"time\": \"12:00\",\n",
    "}\n",
    "requests = download.update_request_date(\n",
    "    request, start=start, stop=stop, stringify_dates=True\n",
    ")\n",
    "chunks = {\"year\": 1, \"month\": 1}\n",
    "\n",
    "# Parameters to speed up I/O\n",
    "open_mfdataset_kwargs = {\n",
    "    \"concat_dim\": \"forecast_reference_time\",\n",
    "    \"combine\": \"nested\",\n",
    "    \"data_vars\": \"minimal\",\n",
    "    \"coords\": \"minimal\",\n",
    "    \"compat\": \"override\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2828b43f",
   "metadata": {},
   "source": [
    "## Functions to cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a89f9-bd3f-49c1-a76d-72cc28647dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_da(ds):\n",
    "    (varname,) = ds.data_vars\n",
    "    return ds[varname]\n",
    "\n",
    "\n",
    "def rechunk(da, tmpdir=None):\n",
    "    if tmpdir:\n",
    "        # Auto-chunking with dask\n",
    "        chunks = dict(\n",
    "            da.chunk(\n",
    "                {\n",
    "                    dim: -1 if dim == \"forecast_reference_time\" else \"auto\"\n",
    "                    for dim in da.dims\n",
    "                }\n",
    "            )\n",
    "            .unify_chunks()\n",
    "            .chunksizes\n",
    "        )\n",
    "\n",
    "        dataarrays = []\n",
    "        for year, da in da.groupby(\"forecast_reference_time.year\"):\n",
    "            # Split in yearly files\n",
    "            da = da.chunk(chunks | {\"forecast_reference_time\": -1}).unify_chunks()\n",
    "            da.to_zarr(f\"{tmpdir}/{year}.zarr\")\n",
    "            ds = xr.open_dataset(\n",
    "                f\"{tmpdir}/{year}.zarr\", engine=\"zarr\", chunks=dict(da.chunksizes)\n",
    "            )\n",
    "            da = ds.set_coords(da.coords)[da.name]\n",
    "            dataarrays.append(da)\n",
    "        da = xr.concat(dataarrays, \"forecast_reference_time\")\n",
    "\n",
    "    # chunk of size 1 for additional dimensions\n",
    "    da = da.chunk(\n",
    "        **{\n",
    "            dim: 1\n",
    "            for dim in da.dims\n",
    "            if dim not in (\"forecast_reference_time\", \"x\", \"y\")\n",
    "        }\n",
    "    )\n",
    "    da.encoding[\"chunksizes\"] = tuple(map(max, da.chunks))\n",
    "    return da\n",
    "\n",
    "\n",
    "def rechunk_and_reduce(da, reduce_func, **kwargs):\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        return reduce_func(rechunk(da, tmpdir), **kwargs).compute()\n",
    "\n",
    "\n",
    "def compute_time_weighted_reduction(ds, group, func, **kwargs):\n",
    "    da = get_da(ds)\n",
    "    if group:\n",
    "        da = da.groupby(group).map(rechunk_and_reduce, reduce_func=func, **kwargs)\n",
    "    else:\n",
    "        da = rechunk_and_reduce(da, reduce_func=func, **kwargs)\n",
    "    return rechunk(da).to_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79e5446",
   "metadata": {},
   "source": [
    "## Compute time reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c4b313-fc09-4d45-bba8-f7b7df6e7a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps_datasets = {}\n",
    "for group in (None, \"forecast_reference_time.month\"):\n",
    "    dataarrays = []\n",
    "    for func in (\n",
    "        diagnostics.time_weighted_mean,\n",
    "        diagnostics.time_weighted_std,\n",
    "        diagnostics.time_weighted_linear_trend,\n",
    "    ):\n",
    "        print(f\"{group=} {func.__name__=}\")\n",
    "        ds = download.download_and_transform(\n",
    "            collection_id,\n",
    "            requests,\n",
    "            transform_func=compute_time_weighted_reduction,\n",
    "            transform_func_kwargs={\"group\": group, \"func\": func, \"weights\": False},\n",
    "            transform_chunks=False,\n",
    "            chunks=chunks,\n",
    "            **open_mfdataset_kwargs,\n",
    "        )\n",
    "        da = rechunk(get_da(ds)).rename(func.__name__)\n",
    "\n",
    "        # Convert and set attributes\n",
    "        name = func.__name__.replace(\"time_weighted_\", \"\")\n",
    "        attrs = {\"long_name\": f\"{name} of {variable}\".replace(\"_\", \" \").capitalize()}\n",
    "        if func == diagnostics.time_weighted_linear_trend:\n",
    "            with xr.set_options(keep_attrs=True):\n",
    "                da *= 60 * 60 * 24 * 365\n",
    "            attrs[\"units\"] = da.attrs[\"units\"].replace(\"s-1\", \"year-1\")\n",
    "        else:\n",
    "            attrs[\"units\"] = da.attrs[\"units\"]\n",
    "        da.attrs = attrs\n",
    "        dataarrays.append(da)\n",
    "    maps_datasets[group] = xr.merge(dataarrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c24d40c",
   "metadata": {},
   "source": [
    "## Compute spatial weighted reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b3a578-8bc4-4b0f-bf77-bc3c29d3263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataarrays = []\n",
    "for func in (diagnostics.spatial_weighted_mean, diagnostics.spatial_weighted_std):\n",
    "    print(f\"{func.__name__=}\")\n",
    "    ds = download.download_and_transform(\n",
    "        collection_id,\n",
    "        requests,\n",
    "        transform_chunks=True,\n",
    "        transform_func=func,\n",
    "        chunks=chunks,\n",
    "        **open_mfdataset_kwargs,\n",
    "    )\n",
    "    dataarrays.append(get_da(ds).rename(func.__name__))\n",
    "ds_timeseries = xr.merge(dataarrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bdb460",
   "metadata": {},
   "source": [
    "## Plot maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32783d3f-cb40-4803-a1ca-1368a21dd63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in maps_datasets.values():\n",
    "    (col,) = (set(ds.dims) - {\"forecast_reference_time\", \"x\", \"y\"}) or {None}\n",
    "    projection = ccrs.LambertConformal(\n",
    "        central_longitude=ds[\"longitude\"].mean().values,\n",
    "        central_latitude=ds[\"latitude\"].mean().values,\n",
    "    )\n",
    "    for var, da in ds.data_vars.items():\n",
    "        plot_obj = plot.projected_map(\n",
    "            da,\n",
    "            projection=projection,\n",
    "            col=col,\n",
    "            col_wrap=3,\n",
    "        )\n",
    "        gridliners = (\n",
    "            [gl for ax in plot_obj.axs.flat for gl in ax._gridliners]\n",
    "            if col\n",
    "            else plot_obj.axes._gridliners\n",
    "        )\n",
    "        for gl in gridliners:\n",
    "            gl.x_inline = False\n",
    "            gl.xlabel_style = {\"rotation\": -45}\n",
    "        title = f\"{collection_id.replace('-', ' ')}\\nFrom {start} to {stop}\".title()\n",
    "        plt.suptitle(title, y=1, va=\"bottom\") if col else plt.title(title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ecf79d",
   "metadata": {},
   "source": [
    "## Plot timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d9d58f-e050-4dc4-a852-9dbf8bbc9ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ds_timeseries[\"spatial_weighted_mean\"].plot(ax=ax, label=\"mean\")\n",
    "ax.fill_between(\n",
    "    ds_timeseries[\"time\"],\n",
    "    ds_timeseries[\"spatial_weighted_mean\"] - ds_timeseries[\"spatial_weighted_std\"],\n",
    "    ds_timeseries[\"spatial_weighted_mean\"] + ds_timeseries[\"spatial_weighted_std\"],\n",
    "    alpha=0.25,\n",
    "    label=\"mean ± std\",\n",
    ")\n",
    "ax.grid()\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1, 1))\n",
    "_ = ax.set_title(\n",
    "    f\"{collection_id}\\n{domain}\".replace(\"-\", \" \").replace(\"_\", \" \").title()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
