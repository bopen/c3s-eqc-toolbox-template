{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Altimetry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import xarray as xr\n",
    "from c3s_eqc_automatic_quality_control import diagnostics, download, plot\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-notebook\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time period\n",
    "start = \"1993-01\"\n",
    "stop = \"2022-12\"\n",
    "\n",
    "# Region of interest\n",
    "region = \"global\"\n",
    "assert region in (\"black-sea\", \"global\", \"mediterranean\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Define Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = f\"satellite-sea-level-{region}\"\n",
    "request = {\n",
    "    \"version\": \"vDT2021\",\n",
    "    \"variable\": \"daily\",\n",
    "    \"format\": \"zip\",\n",
    "}\n",
    "requests = download.update_request_date(\n",
    "    request, start=start, stop=stop, stringify_dates=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Functions to cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rechunk(da, tmpdir):\n",
    "    da = da.sortby(\"time\")\n",
    "    da.encoding = {}\n",
    "\n",
    "    target_store = f\"{tmpdir}/temporary.zarr\"\n",
    "    append_dim = None\n",
    "    for _, da_chunk in tqdm.tqdm(da.resample(time=\"5D\")):\n",
    "        da_chunk.chunk(time=-1).to_zarr(target_store, append_dim=append_dim)\n",
    "        append_dim = \"time\"\n",
    "    da = xr.open_dataarray(target_store, chunks={}, engine=\"zarr\")\n",
    "    da.encoding = {}\n",
    "\n",
    "    target_store = f\"{tmpdir}/target.zarr\"\n",
    "    da = da.chunk(time=5_000, latitude=10, longitude=10)\n",
    "    da.to_zarr(target_store)\n",
    "    return xr.open_dataarray(target_store, chunks={}, engine=\"zarr\")\n",
    "\n",
    "\n",
    "def compute_extreme(da):\n",
    "    da_95 = (\n",
    "        da.chunk(\n",
    "            {\n",
    "                dim: -1 if dim == \"time\" else chunksize\n",
    "                for dim, chunksize in da.chunksizes.items()\n",
    "            }\n",
    "        )\n",
    "        .quantile(q=0.95, dim=\"time\")\n",
    "        .drop_vars(\"quantile\")\n",
    "    )\n",
    "    da_extreme = da.where(da > da_95).mean(\"time\")\n",
    "    da_extreme.attrs = {\n",
    "        \"units\": da.attrs[\"units\"],\n",
    "        \"long_name\": f\"Mean extrema of {da.attrs['long_name']}\",\n",
    "    }\n",
    "    return da_extreme.rename(\"extreme\")\n",
    "\n",
    "\n",
    "def compute_time_statistics(ds, reductions):\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        print(f\"{tmpdir=}\")\n",
    "        da = rechunk(ds[\"sla\"], tmpdir)\n",
    "        dataarrays = []\n",
    "        for reduction in reductions:\n",
    "            print(f\"{reduction=}\")\n",
    "            if reduction == \"extreme\":\n",
    "                da_reduced = compute_extreme(da)\n",
    "            else:\n",
    "                da_reduced = getattr(diagnostics, f\"time_weighted_{reduction}\")(\n",
    "                    da, weights=False\n",
    "                )\n",
    "                da_reduced.attrs = {\n",
    "                    \"units\": da_reduced.attrs[\"units\"],\n",
    "                    \"long_name\": f\"{reduction.capitalize().replace('_', ' ')} of {da.attrs['long_name']}\",\n",
    "                }\n",
    "            dataarrays.append(da_reduced.rename(reduction).compute())\n",
    "    return xr.merge(dataarrays)\n",
    "\n",
    "\n",
    "def compute_spatial_weighted_statistics(ds):\n",
    "    da = ds[\"sla\"].chunk(latitude=-1, longitude=-1)\n",
    "    ds_diag = diagnostics.spatial_weighted_statistics(da).to_dataset(dim=\"diagnostic\")\n",
    "    for reduction, da_reduced in ds_diag.data_vars.items():\n",
    "        da_reduced.attrs = {\n",
    "            \"units\": da.attrs[\"units\"],\n",
    "            \"long_name\": f\"Spatial weighted {reduction} of {da.attrs['long_name']}\",\n",
    "        }\n",
    "    return ds_diag"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Chunking and I/O keyword arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = {\"year\": 1}\n",
    "xarray_kwargs = {\n",
    "    # Speedup IO\n",
    "    \"concat_dim\": \"time\",\n",
    "    \"combine\": \"nested\",\n",
    "    \"data_vars\": \"minimal\",\n",
    "    \"coords\": \"minimal\",\n",
    "    \"compat\": \"override\",\n",
    "}\n",
    "download_and_transform_kwargs = {\"chunks\": chunks} | xarray_kwargs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Compute time reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_maps = download.download_and_transform(\n",
    "    collection_id,\n",
    "    requests,\n",
    "    transform_func=compute_time_statistics,\n",
    "    transform_func_kwargs={\n",
    "        \"reductions\": (\"mean\", \"std\", \"coverage\", \"linear_trend\", \"extreme\")\n",
    "    },\n",
    "    transform_chunks=False,\n",
    "    **download_and_transform_kwargs,\n",
    ")\n",
    "\n",
    "# Convert units\n",
    "with xr.set_options(keep_attrs=True):\n",
    "    ds_maps[\"linear_trend\"] *= 1.0e3 * 60 * 60 * 24 * 365\n",
    "ds_maps[\"linear_trend\"].attrs[\"units\"] = \"mm/year\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Compute spatial weighted reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_timeseries = download.download_and_transform(\n",
    "    collection_id,\n",
    "    requests,\n",
    "    transform_func=compute_spatial_weighted_statistics,\n",
    "    cached_open_mfdataset_kwargs=True,\n",
    "    **download_and_transform_kwargs,\n",
    ").sortby(\"time\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Plot maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "central_longitude = ds_maps[\"longitude\"].mean().values\n",
    "if region == \"global\":\n",
    "    projection = ccrs.Robinson(central_longitude=central_longitude)\n",
    "else:\n",
    "    projection = ccrs.Mercator(\n",
    "        central_longitude=central_longitude,\n",
    "        min_latitude=ds_maps[\"latitude\"].min().values,\n",
    "        max_latitude=ds_maps[\"latitude\"].max().values,\n",
    "    )\n",
    "for var, da in ds_maps.data_vars.items():\n",
    "    plot.projected_map(\n",
    "        da,\n",
    "        projection=projection,\n",
    "        robust=True,\n",
    "        center=0 if var in (\"mean\", \"linear_trend\") else None,\n",
    "    )\n",
    "    plt.title(f\"{da.attrs['long_name']} ({start}, {stop})\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Plot timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 365\n",
    "ds_to_plot = {\n",
    "    \"Daily\": ds_timeseries,\n",
    "    f\"{window}-day rolling mean\": ds_timeseries.rolling(time=window, center=True).mean(\n",
    "        keep_attrs=True\n",
    "    ),\n",
    "}\n",
    "\n",
    "for title, ds in ds_to_plot.items():\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    for var, da in ds.data_vars.items():\n",
    "        da.plot(label=var, ax=ax)\n",
    "    ax.grid()\n",
    "    ax.set_title(\"\\n\".join([da.attrs[\"long_name\"].split(\" of \")[-1], title]))\n",
    "    ax.set_ylabel(f\"[{da.attrs['units']}]\")\n",
    "    ax.legend(title=\"Spatial weighted\", bbox_to_anchor=(1, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
