{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Drought index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from c3s_eqc_automatic_quality_control import diagnostics, download, plot\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time\n",
    "start = \"2000-01\"\n",
    "stop = \"2022-12\"\n",
    "index_slice = slice(\"2022-06-01\", \"2022-09-30\")\n",
    "\n",
    "# Max value allowed\n",
    "threshold = -1.5\n",
    "\n",
    "# Space\n",
    "area = [58, -10, 36, 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Define requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests = {\n",
    "    \"Reanalysis\": (\n",
    "        \"derived-era5-single-levels-daily-statistics\",\n",
    "        {\n",
    "            \"product_type\": \"reanalysis\",\n",
    "            \"variable\": [\"volumetric_soil_water_layer_1\", \"land_sea_mask\"],\n",
    "            \"daily_statistic\": \"daily_mean\",\n",
    "            \"time_zone\": \"utc+00:00\",\n",
    "            \"frequency\": \"1_hourly\",\n",
    "            \"area\": area,\n",
    "        },\n",
    "    ),\n",
    "    \"Satellite\": (\n",
    "        \"satellite-soil-moisture\",\n",
    "        {\n",
    "            \"variable\": [\"volumetric_surface_soil_moisture\"],\n",
    "            \"type_of_sensor\": [\"combined_passive_and_active\"],\n",
    "            \"time_aggregation\": [\"day_average\"],\n",
    "            \"type_of_record\": [\"cdr\"],\n",
    "            \"version\": [\"v202312\"],\n",
    "        },\n",
    "    ),\n",
    "}\n",
    "target_grid_request = (\n",
    "    \"reanalysis-era5-single-levels\",\n",
    "    {\n",
    "        \"product_type\": [\"reanalysis\"],\n",
    "        \"variable\": [\"land_sea_mask\"],\n",
    "        \"year\": [\"1940\"],\n",
    "        \"month\": [\"01\"],\n",
    "        \"day\": [\"01\"],\n",
    "        \"time\": [\"00:00\"],\n",
    "        \"data_format\": \"grib\",\n",
    "        \"download_format\": \"unarchived\",\n",
    "        \"area\": area,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Define functions to cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(obj, window):\n",
    "    obj = obj.chunk(time=-1)\n",
    "    return obj.interpolate_na(\"time\").rolling(time=window, min_periods=1).mean()\n",
    "\n",
    "\n",
    "def compute_anomaly_drought_index(ds, threshold, target_grid_request, **xesmf_kwargs):\n",
    "    # Get raw data\n",
    "    (var_name,) = set(ds.data_vars) & {\"sm\", \"swvl1\"}\n",
    "    raw_data = ds[var_name]\n",
    "\n",
    "    # Mask\n",
    "    if (lsm := ds.get(\"lsm\")) is not None:\n",
    "        raw_data = raw_data.where((lsm > 0.5).all(\"time\"))\n",
    "\n",
    "    # Interpolate\n",
    "    if target_grid_request:\n",
    "        grid_out = download.download_and_transform(\n",
    "            *target_grid_request, invalidate_cache=False\n",
    "        )\n",
    "        grid_out = grid_out[[\"latitude\", \"longitude\"]]\n",
    "        grid_out = grid_out.drop_vars(set(grid_out.variables) - set(grid_out.dims))\n",
    "        raw_data = diagnostics.regrid(raw_data, grid_out, **xesmf_kwargs)\n",
    "    else:\n",
    "        assert not xesmf_kwargs\n",
    "\n",
    "    # Get time-varying index\n",
    "    group_dim = \"time.dayofyear\"\n",
    "    smooth_data_grouped = smooth(raw_data, 11).groupby(group_dim)\n",
    "    sma = raw_data.groupby(group_dim) - smooth_data_grouped.mean()\n",
    "    sma = sma.groupby(group_dim) / smooth_data_grouped.std()\n",
    "    sma = smooth(sma, 3)\n",
    "    sma = sma.where(sma < threshold)\n",
    "    sma.attrs = {\"long_name\": \"Anomaly drought index\", \"units\": \"1\"}\n",
    "    return sma.rename(\"sma\")\n",
    "\n",
    "\n",
    "def compute_severity(sma):\n",
    "    severity = sma.sum(\"time\")\n",
    "    severity = severity.where(severity)\n",
    "    severity.attrs = {\"long_name\": \"Severity\", \"units\": \"1\"}\n",
    "    return severity.rename(\"severity\")\n",
    "\n",
    "\n",
    "def compute_timeseries(ds, threshold, target_grid_request, **xesmf_kwargs):\n",
    "    da = compute_anomaly_drought_index(\n",
    "        ds, threshold=threshold, target_grid_request=target_grid_request, **xesmf_kwargs\n",
    "    )\n",
    "    return diagnostics.spatial_weighted_mean(da).to_dataset()\n",
    "\n",
    "\n",
    "def compute_maps(ds, threshold, index_slice, target_grid_request, **xesmf_kwargs):\n",
    "    sma = compute_anomaly_drought_index(\n",
    "        ds, threshold, target_grid_request, **xesmf_kwargs\n",
    "    )\n",
    "    sma = sma.sel(time=index_slice)\n",
    "    severity = compute_severity(sma)\n",
    "    return xr.merge([sma.min(\"time\", keep_attrs=True), severity])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Download and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_maps = []\n",
    "datasets_timeseries = []\n",
    "for product, (collection_id, request) in requests.items():\n",
    "    print(f\"{product = }\")\n",
    "    request = download.update_request_date(request, start, stop, stringify_dates=True)\n",
    "    kwargs = {\"threshold\": threshold, \"target_grid_request\": None}\n",
    "    if product == \"Satellite\":\n",
    "        kwargs[\"target_grid_request\"] = target_grid_request\n",
    "        kwargs[\"method\"] = \"conservative\"\n",
    "\n",
    "    # Map\n",
    "    ds = download.download_and_transform(\n",
    "        collection_id,\n",
    "        request,\n",
    "        chunks={\"year\": 1, \"month\": 1},\n",
    "        transform_func=compute_maps,\n",
    "        transform_func_kwargs=kwargs | {\"index_slice\": index_slice},\n",
    "        transform_chunks=False,\n",
    "    )\n",
    "    datasets_maps.append(ds.expand_dims(product=[product]))\n",
    "\n",
    "    # Timeseries\n",
    "    ds = download.download_and_transform(\n",
    "        collection_id,\n",
    "        request,\n",
    "        chunks={\"year\": 1, \"month\": 1},\n",
    "        transform_func=compute_timeseries,\n",
    "        transform_func_kwargs=kwargs,\n",
    "        transform_chunks=False,\n",
    "    )\n",
    "    datasets_timeseries.append(ds.expand_dims(product=[product]))\n",
    "ds_maps = xr.combine_by_coords(datasets_maps)\n",
    "ds_timeseries = xr.combine_by_coords(datasets_timeseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Plot timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_timeseries[\"sma\"].plot(hue=\"product\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Plot maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable, da in ds_maps.data_vars.items():\n",
    "    # Products\n",
    "    match variable:\n",
    "        case \"sma\":\n",
    "            colors = [\"#fe0000\", \"#fc7f01\", \"#ff9f00\", \"#febd01\", \"#fee819\", \"#e4ff7a\"]\n",
    "            levels = [-8.0, -6.0, -5.0, -4.0, -3.0, -2.0, -1.5]\n",
    "        case \"severity\":\n",
    "            colors = [\"#fe0000\", \"#fc7f01\", \"#ff9f00\", \"#febd01\", \"#fee819\", \"#e4ff7a\"]\n",
    "            levels = [-300, -250, -200, -150, -100, -50, 0]\n",
    "        case _:\n",
    "            raise NotImplementedError(f\"{variable = }\")\n",
    "    cmap = mcolors.ListedColormap(colors)\n",
    "    norm = mcolors.BoundaryNorm(levels, cmap.N)\n",
    "    plot.projected_map(da, levels=levels, cmap=cmap, norm=norm, col=\"product\")\n",
    "    plt.show()\n",
    "\n",
    "    # Bias\n",
    "    with xr.set_options(keep_attrs=True):\n",
    "        bias = da.diff(\"product\").drop_vars(\"product\")\n",
    "    bias.attrs[\"long_name\"] = \"Bias of \" + bias.long_name\n",
    "    plot.projected_map(bias)\n",
    "    plt.title(\" - \".join(da[\"product\"].values.tolist()[::-1]))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
