{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# XCH4 dataset satellite lev2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import flox.xarray\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from c3s_eqc_automatic_quality_control import diagnostics, download, plot\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Define request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time parameters\n",
    "year_start = 2005\n",
    "year_stop = 2006\n",
    "\n",
    "collection_id = \"satellite-methane\"\n",
    "request = {\n",
    "    \"processing_level\": \"level_2\",\n",
    "    \"variable\": \"xch4\",\n",
    "    \"sensor_and_algorithm\": \"merged_emma\",\n",
    "    \"version\": \"4.4\",\n",
    "    \"year\": [\n",
    "        str(year) for year in range(year_start - 1, year_stop + 1)\n",
    "    ],  # Download previous year to include Dec\n",
    "    \"month\": [f\"{i:02d}\" for i in range(1, 13)],\n",
    "    \"day\": [f\"{i:02d}\" for i in range(1, 32)],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Define function to cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arithmetic_unweighted_average(ds, d_lon, d_lat, lon1):\n",
    "    if lon1 not in (180, 360):\n",
    "        raise ValueError(f\"lon1 must be 180 or 360. {lon1=}\")\n",
    "    lon0 = -180 if lon1 == 180 else 0\n",
    "\n",
    "    coords = {}\n",
    "    expected_groups = ()\n",
    "    for name, start, stop, step in zip(\n",
    "        [\"latitude\", \"longitude\"], [-90, lon0], [90, lon1], [d_lat, d_lon]\n",
    "    ):\n",
    "        coords[name] = np.arange(start + step / 2, stop + step / 2, step)\n",
    "        groups = np.arange(start, stop + step, step)\n",
    "        groups[0] -= step\n",
    "        expected_groups += (pd.IntervalIndex.from_breaks(groups),)\n",
    "\n",
    "    ds = flox.xarray.xarray_reduce(\n",
    "        ds, *coords, func=\"mean\", expected_groups=expected_groups, keep_attrs=True\n",
    "    )\n",
    "    ds = ds.rename({f\"{coord}_bins\": coord for coord in coords}).assign_coords(coords)\n",
    "    for coord in ds.coords:\n",
    "        ds[coord].attrs[\"standard_name\"] = coord\n",
    "    return ds\n",
    "\n",
    "\n",
    "def monthly_regrid(ds, d_lon, d_lat, lon1=180):\n",
    "    \"\"\"Resample to monthly regular grid.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds: Dataset\n",
    "        Dataset to resample\n",
    "    d_lon, d_lat: int\n",
    "        Longitude/latitude step size\n",
    "    lon1: int, {180, 360}\n",
    "        Right longitude bound. According to which convention is used,\n",
    "        longitudes will vary from -180 to 180 or from 0 to 360.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dataset\n",
    "    \"\"\"\n",
    "    ds = ds.set_coords([\"longitude\", \"latitude\"])\n",
    "    ds_out = ds.resample(time=\"1MS\").map(\n",
    "        arithmetic_unweighted_average, d_lon=d_lon, d_lat=d_lat, lon1=lon1\n",
    "    )\n",
    "    return ds_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Download and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = download.download_and_transform(\n",
    "    collection_id,\n",
    "    request,\n",
    "    chunks={\"year\": 1},\n",
    "    transform_func=monthly_regrid,\n",
    "    transform_func_kwargs={\"d_lon\": 1, \"d_lat\": 1, \"lon1\": 180},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Compute seasonal anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select years (shift -1 to get D(year-1)J(year)F(year))\n",
    "ds = ds.assign_coords(year=ds[\"time\"].dt.year.shift(time=-1).astype(int))\n",
    "mask = (ds[\"year\"] >= year_start) & (ds[\"year\"] <= year_stop)\n",
    "ds = ds.where(mask.compute(), drop=True)\n",
    "\n",
    "# Compute anomaly\n",
    "climatology = diagnostics.seasonal_weighted_mean(ds)\n",
    "with xr.set_options(keep_attrs=True):\n",
    "    anomaly = ds.groupby(\"year\").map(diagnostics.seasonal_weighted_mean) - climatology\n",
    "\n",
    "# Update attributes\n",
    "for da in anomaly.data_vars.values():\n",
    "    if \"long_name\" in da.attrs:\n",
    "        da.attrs[\"long_name\"] += \" Anomaly\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Plot seasonal anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot.projected_map(\n",
    "    anomaly[\"xch4\"], projection=ccrs.Robinson(), col=\"season\", row=\"year\", robust=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
