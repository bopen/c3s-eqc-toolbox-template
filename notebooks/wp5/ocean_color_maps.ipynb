{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Ocean color reflectance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import cacholote\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import xarray as xr\n",
    "from c3s_eqc_automatic_quality_control import diagnostics, download, plot, utils\n",
    "from xarrayMannKendall import Mann_Kendall_test\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Time period\n",
    "year_start = 1998\n",
    "year_stop = 2022\n",
    "\n",
    "# Variable to analyse\n",
    "variable = \"Rrs_443\"\n",
    "assert variable in (\n",
    "    \"chlor_a\",\n",
    "    \"Rrs_412\",\n",
    "    \"Rrs_443\",\n",
    "    \"Rrs_490\",\n",
    "    \"Rrs_510\",\n",
    "    \"Rrs_560\",\n",
    "    \"Rrs_665\",\n",
    ")\n",
    "\n",
    "# Regions to plot\n",
    "regions = {\n",
    "    \"Global\": {\"lon_slice\": slice(-180, 180), \"lat_slice\": slice(90, -90)},\n",
    "    \"50S-50N\": {\"lon_slice\": slice(-180, 180), \"lat_slice\": slice(50, -50)},\n",
    "    \"15-30N 40-55W\": {\"lon_slice\": slice(-55, -40), \"lat_slice\": slice(30, 15)},\n",
    "    \"NASTG\": {\"lon_slice\": slice(-80, 0), \"lat_slice\": slice(50, 0)},\n",
    "}\n",
    "for region, slices in regions.items():\n",
    "    # Enforce sorting as original data\n",
    "    for k, v in slices.items():\n",
    "        assert v.start >= v.stop if k == \"lat_slice\" else v.start <= v.stop, (region, k)\n",
    "\n",
    "# Save figures\n",
    "savefig = False\n",
    "assert isinstance(savefig, bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Define request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = \"satellite-ocean-colour\"\n",
    "\n",
    "request = {\n",
    "    \"variable\": \"remote_sensing_reflectance\"\n",
    "    if variable.startswith(\"Rrs\")\n",
    "    else \"mass_concentration_of_chlorophyll_a\",\n",
    "    \"projection\": \"regular_latitude_longitude_grid\",\n",
    "    \"version\": \"6_0\",\n",
    "    \"format\": \"zip\",\n",
    "}\n",
    "\n",
    "# Parameters to speed up I/O\n",
    "open_mfdataset_kwargs = {\n",
    "    \"concat_dim\": \"time\",\n",
    "    \"combine\": \"nested\",\n",
    "    \"data_vars\": \"minimal\",\n",
    "    \"coords\": \"minimal\",\n",
    "    \"compat\": \"override\",\n",
    "    \"parallel\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Functions to cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rechunk(obj):\n",
    "    chunks = {\"year\": 1, \"time\": -1, \"longitude\": 270, \"latitude\": 270, \"reduction\": 1}\n",
    "    return obj.chunk(**{k: v for k, v in chunks.items() if k in obj.dims})\n",
    "\n",
    "\n",
    "def rrs_monthly_weighted_log_reductions(ds, variable):\n",
    "    da = rechunk(ds[variable])\n",
    "    if variable == \"chlor_a\":\n",
    "        da = da.where((da > 1.0e-3) & (da < 1.0e2))\n",
    "    weights = np.abs(np.cos(np.deg2rad(da[\"latitude\"])))\n",
    "    with xr.set_options(keep_attrs=True):\n",
    "        da = np.log10(da)\n",
    "        da = da.groupby(\"time.year\").map(\n",
    "            diagnostics.monthly_weighted_mean, weights=False\n",
    "        )\n",
    "        da = 10 ** (da + np.log10(weights))\n",
    "        da = da.persist()\n",
    "        da_mean = da.mean(\"month\").expand_dims(reduction=[\"mean\"])\n",
    "        da_std = (10 ** np.log10(da).std(\"month\")).expand_dims(reduction=[\"std\"])\n",
    "    da = xr.concat([da_mean, da_std], \"reduction\")\n",
    "    da.attrs[\"long_name\"] = da.attrs[\"long_name\"].replace(\" (not log-transformed)\", \"\")\n",
    "    da.encoding[\"chunksizes\"] = tuple(map(max, da.chunks))\n",
    "    return da.to_dataset(name=variable)\n",
    "\n",
    "\n",
    "def get_yearly_mean_and_std(\n",
    "    collection_id, request, year_start, year_stop, variable, **open_mfdataset_kwargs\n",
    "):\n",
    "    datasets = []\n",
    "    for year in tqdm.tqdm(range(year_start, year_stop + 1), desc=\"year\"):\n",
    "        requests = download.update_request_date(\n",
    "            request, start=f\"{year}-01\", stop=f\"{year}-12\", stringify_dates=True\n",
    "        )\n",
    "        ds = download.download_and_transform(\n",
    "            collection_id,\n",
    "            requests,\n",
    "            transform_chunks=False,\n",
    "            transform_func=rrs_monthly_weighted_log_reductions,\n",
    "            transform_func_kwargs={\"variable\": variable},\n",
    "            chunks={\"year\": 1, \"month\": 1},\n",
    "            **open_mfdataset_kwargs,\n",
    "        )\n",
    "        datasets.append(rechunk(ds))\n",
    "    return xr.concat(datasets, \"year\")\n",
    "\n",
    "\n",
    "@cacholote.cacheable\n",
    "def get_diagnostics_from_yearly_mean_and_std(\n",
    "    collection_id,\n",
    "    request,\n",
    "    year_start,\n",
    "    year_stop,\n",
    "    variable,\n",
    "    mann_kendall_kwargs,\n",
    "    **open_mfdataset_kwargs,\n",
    "):\n",
    "    da = get_yearly_mean_and_std(\n",
    "        collection_id=collection_id,\n",
    "        request=request,\n",
    "        year_start=year_start,\n",
    "        year_stop=year_stop,\n",
    "        variable=variable,\n",
    "        **open_mfdataset_kwargs,\n",
    "    )[variable]\n",
    "\n",
    "    ds_in = rechunk(da).to_dataset(dim=\"reduction\")\n",
    "    ds_in = ds_in.chunk({dim: -1 if dim == \"year\" else \"auto\" for dim in ds_in.dims})\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        ds_in.to_zarr(tmpdir)\n",
    "        ds_in = xr.open_dataset(tmpdir, engine=\"zarr\", chunks=dict(ds_in.chunksizes))\n",
    "\n",
    "        # Trend\n",
    "        coords_name = {\"time\": \"year\", \"x\": \"longitude\", \"y\": \"latitude\"}\n",
    "        ds_out = Mann_Kendall_test(\n",
    "            ds_in[\"mean\"], coords_name=coords_name, **mann_kendall_kwargs\n",
    "        ).compute()\n",
    "        ds_out[\"trend\"].attrs = {\n",
    "            \"long_name\": f\"Trend of {da.attrs['long_name']}\",\n",
    "            \"units\": f\"{da.attrs['units']}/year\",\n",
    "        }\n",
    "        ds_out = ds_out.rename({k: v for k, v in coords_name.items() if k != \"time\"})\n",
    "\n",
    "        # Mean and std\n",
    "        ds_out[\"mean\"] = ds_in[\"mean\"].mean(\"year\")\n",
    "        ds_out[\"std\"] = (ds_in[\"std\"] ** 2).mean(\"year\") ** 0.5\n",
    "        ds_out[\"mean\"].attrs = ds_out[\"std\"].attrs = da.attrs\n",
    "        return ds_out.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Download and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"collection_id\": collection_id,\n",
    "    \"request\": request,\n",
    "    \"year_start\": year_start,\n",
    "    \"year_stop\": year_stop,\n",
    "    \"variable\": variable,\n",
    "} | open_mfdataset_kwargs\n",
    "mann_kendall_kwargs = {\"alpha\": 0.5, \"method\": \"theilslopes\"}\n",
    "\n",
    "ds = get_diagnostics_from_yearly_mean_and_std(\n",
    "    mann_kendall_kwargs=mann_kendall_kwargs, **kwargs\n",
    ")\n",
    "da_year = rechunk(get_yearly_mean_and_std(**kwargs)[variable])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Plot maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "da = ds[[\"mean\", \"std\"]].to_array(dim=\"reduction\")\n",
    "da_year_low_res = da_year.coarsen({\"latitude\": 5, \"longitude\": 5}).mean()\n",
    "\n",
    "plot_kwargs = {}\n",
    "for region, regionalise_kwargs in regions.items():\n",
    "    # Compute all plot kwargs once based on overall stats\n",
    "    da_region = utils.regionalise(da, **regionalise_kwargs)\n",
    "    kwargs_reductions = {}\n",
    "    for reduction, da_reduction in da_region.groupby(\"reduction\"):\n",
    "        kwargs_reductions[reduction] = xr.plot.utils._determine_cmap_params(\n",
    "            da_reduction.values, robust=True\n",
    "        )\n",
    "    plot_kwargs[region] = kwargs_reductions\n",
    "\n",
    "for da_to_plot in [da, da_year_low_res]:\n",
    "    for region, regionalise_kwargs in regions.items():\n",
    "        da_region = utils.regionalise(da_to_plot, **regionalise_kwargs)\n",
    "        for reduction, da_reduction in da_region.groupby(\"reduction\"):\n",
    "            plot.projected_map(\n",
    "                da_reduction,\n",
    "                col=\"year\" if \"year\" in da_to_plot.dims else None,\n",
    "                col_wrap=5,\n",
    "                show_stats=False,\n",
    "                **plot_kwargs[region][reduction],\n",
    "            )\n",
    "            title = [reduction.capitalize(), region, f\"{year_start}-{year_stop}\"]\n",
    "            if \"year\" in da_to_plot.dims:\n",
    "                title.append(\"Yearly\")\n",
    "            title = \" \".join(title)\n",
    "            plt.suptitle(title) if \"year\" in da_to_plot.dims else plt.title(title)\n",
    "            if savefig:\n",
    "                plt.savefig(title.replace(\" \", \"_\").lower() + \".png\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Plot trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.projected_map(ds[\"trend\"], show_stats=False, robust=True, center=0)\n",
    "_ = plot.projected_map(\n",
    "    ds[\"p\"],\n",
    "    show_stats=False,\n",
    "    cmap=\"none\",\n",
    "    add_colorbar=False,\n",
    "    plot_func=\"contourf\",\n",
    "    levels=[0, 0.05, 1],\n",
    "    hatches=[\"\", \"/\" * 5],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
