{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Tropopause"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cdsapi\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from c3s_eqc_automatic_quality_control import download\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time period\n",
    "start = \"2006-05\"\n",
    "stop = \"2020-03\"\n",
    "\n",
    "# Stations\n",
    "stations = [\"TEN\", \"LIN\", \"NYA\"]  # Use None to analyse all stations\n",
    "assert isinstance(stations, list | None)\n",
    "\n",
    "# CDS credentials\n",
    "os.environ[\"CDSAPI_RC\"] = os.path.expanduser(\"~/ciardini_virginia/.cdsapirc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Define request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = \"insitu-observations-gruan-reference-network\"\n",
    "request = {\n",
    "    \"variable\": [\n",
    "        \"air_temperature\",\n",
    "        \"relative_humidity\",\n",
    "        \"air_pressure\",\n",
    "        \"altitude\",\n",
    "        \"water_vapour_mixing_ratio\",\n",
    "    ],\n",
    "    \"data_format\": \"netcdf\",\n",
    "}\n",
    "\n",
    "client = cdsapi.Client()\n",
    "requests = []\n",
    "for date in pd.date_range(start, stop, freq=\"1MS\"):\n",
    "    time_request = {\"year\": date.strftime(\"%Y\"), \"month\": date.strftime(\"%m\")}\n",
    "    time_request[\"day\"] = client.client.apply_constraints(\n",
    "        collection_id, request | time_request\n",
    "    )[\"day\"]\n",
    "    if time_request[\"day\"]:\n",
    "        requests.append(request | time_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Functions to cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reorganize_dataset(ds):\n",
    "    # Rename\n",
    "    (varname,) = set(ds[\"observed_variable\"].values)\n",
    "    ds = ds.rename(observation_value=str(varname)).drop_vars(\"observed_variable\")\n",
    "    ds = ds.rename(\n",
    "        {\n",
    "            var: \"_\".join([varname, var.replace(\"_value\", \"\")])\n",
    "            for var in ds.data_vars\n",
    "            if var.startswith(\"uncertainty\")\n",
    "        }\n",
    "    )\n",
    "    # Update attrs\n",
    "    for var, da in ds.data_vars.items():\n",
    "        match var:\n",
    "            case \"pressure\":\n",
    "                da.attrs[\"long_name\"] = \"Pressure\"\n",
    "            case \"air_temperature\":\n",
    "                da.attrs[\"long_name\"] = \"Temperature\"\n",
    "            case \"altitude\":\n",
    "                da.attrs[\"long_name\"] = \"Altitude\"\n",
    "            case \"relative_humidity\":\n",
    "                da.attrs[\"long_name\"] = \"Relative\"\n",
    "            case \"water_vapour_mixing_ratio\":\n",
    "                da.attrs[\"long_name\"] = \"Mixing\"\n",
    "        for string in (\"units\", \"type\"):\n",
    "            if string in var:\n",
    "                ds = ds.drop_vars(var)\n",
    "                (value,) = set(da.values)\n",
    "                attrs_var = varname if var == string else var.replace(\"_\" + string, \"\")\n",
    "                ds[attrs_var].attrs[string] = value\n",
    "    return ds\n",
    "\n",
    "\n",
    "def reorganize_dataset(ds, stations):\n",
    "    for var, da in ds.data_vars.items():\n",
    "        if np.issubdtype(da.dtype, np.bytes_):\n",
    "            ds[var].values = np.char.decode(da.values, \"utf-8\")\n",
    "\n",
    "    if stations is not None:\n",
    "        ds = ds.where(ds[\"primary_station_id\"].isin(stations), drop=True)\n",
    "\n",
    "    if not ds.sizes[\"index\"]:\n",
    "        return ds\n",
    "\n",
    "    datasets = []\n",
    "    for var, ds in ds.groupby(\"observed_variable\"):\n",
    "        datasets.append(_reorganize_dataset(ds))\n",
    "    ds = xr.merge(datasets)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Download and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = download.download_and_transform(\n",
    "    collection_id,\n",
    "    requests,\n",
    "    chunks={\"year\": 1, \"month\": 1},\n",
    "    transform_func=reorganize_dataset,\n",
    "    transform_func_kwargs={\"stations\": sorted(stations) if stations else stations},\n",
    "    cached_open_mfdataset_kwargs={\"concat_dim\": \"index\", \"combine\": \"nested\"},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
