{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Insitu precipitation completeness for climate monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymannkendall as mk\n",
    "import scipy.stats\n",
    "import xarray as xr\n",
    "from c3s_eqc_automatic_quality_control import diagnostics, download, plot\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time periods\n",
    "years_start = [1951, 1961, 1971, 1981, 1991]\n",
    "years_stop = [1980, 1990, 2000, 2010, 2020]\n",
    "colors = [\"deepskyblue\", \"green\", \"gold\", \"darkorange\", \"red\"]\n",
    "assert len(years_start) == len(years_stop) == len(colors)\n",
    "\n",
    "# Region of interst\n",
    "area = [44, -10, 36, 1]  # N, W, S, E\n",
    "assert len(area) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Define request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = \"insitu-gridded-observations-europe\"\n",
    "request = {\n",
    "    \"variable\": [\"precipitation_amount\"],\n",
    "    \"grid_resolution\": \"0_25deg\",\n",
    "    \"period\": \"full_period\",\n",
    "    \"version\": [\"28_0e\"],\n",
    "    \"area\": area,\n",
    "}\n",
    "\n",
    "collection_id_era5 = \"reanalysis-era5-single-levels\"\n",
    "request_era5 = {\n",
    "    \"product_type\": [\"ensemble_mean\"],\n",
    "    \"variable\": [\"total_precipitation\"],\n",
    "    \"time\": [f\"{hour:02d}:00\" for hour in range(0, 24, 3)],\n",
    "    \"area\": area,\n",
    "}\n",
    "start = f\"{min(years_start)}-01\"\n",
    "stop = f\"{max(years_stop)}-12\"\n",
    "requests_era5 = download.update_request_date(request_era5, start, stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Define function to cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dayofyear_reindex(ds, years_start, years_stop):\n",
    "    # 15-day rolling mean\n",
    "    ds_rolled = ds.rolling(time=15, center=True).mean()\n",
    "\n",
    "    # Extract periods\n",
    "    datasets = []\n",
    "    for year_start, year_stop in zip(years_start, years_stop):\n",
    "        period = f\"{year_start}-{year_stop}\"\n",
    "        ds_masked = ds_rolled.where(\n",
    "            (ds_rolled[\"time\"].dt.year >= year_start)\n",
    "            & (ds_rolled[\"time\"].dt.year <= year_stop),\n",
    "            drop=True,\n",
    "        )\n",
    "        datasets.append(\n",
    "            ds_masked.groupby(\"time.dayofyear\").mean().expand_dims(period=[period])\n",
    "        )\n",
    "    ds_dayofyear = xr.merge(datasets)\n",
    "\n",
    "    # Add season (pick any leap year)\n",
    "    season = xr.DataArray(\n",
    "        pd.to_datetime(ds_dayofyear[\"dayofyear\"].values - 1, unit=\"D\", origin=\"2008\"),\n",
    "    ).dt.season\n",
    "    return ds_dayofyear.assign_coords(season=(\"dayofyear\", season.values))\n",
    "\n",
    "\n",
    "def accumulated_spatial_weighted_mean(ds):\n",
    "    ds = ds.resample(time=\"1D\").sum(keep_attrs=True)\n",
    "    return diagnostics.spatial_weighted_mean(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Download and compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataarrays = []\n",
    "for reduction in (\"mean\", \"spread\"):\n",
    "    print(f\"{reduction=}\")\n",
    "    da = download.download_and_transform(\n",
    "        collection_id,\n",
    "        request | {\"product_type\": f\"ensemble_{reduction}\"},\n",
    "        transform_func=dayofyear_reindex,\n",
    "        transform_func_kwargs={\"years_start\": years_start, \"years_stop\": years_stop},\n",
    "    )[\"rr\"]\n",
    "    dataarrays.append(da.rename(reduction))\n",
    "    da.attrs[\"long_name\"] += f\" {reduction}\"\n",
    "ds_periods = xr.merge(dataarrays)\n",
    "\n",
    "# Timeseries\n",
    "da_eobs = download.download_and_transform(\n",
    "    collection_id,\n",
    "    request | {\"product_type\": \"ensemble_mean\"},\n",
    "    transform_func=diagnostics.spatial_weighted_mean,\n",
    ")[\"rr\"]\n",
    "da_eobs = da_eobs.sel(time=slice(start, stop))\n",
    "\n",
    "da_era5 = download.download_and_transform(\n",
    "    collection_id_era5,\n",
    "    requests_era5,\n",
    "    transform_func=accumulated_spatial_weighted_mean,\n",
    "    backend_kwargs={\"time_dims\": [\"valid_time\"]},\n",
    "    chunks={\"year\": 1},\n",
    ")[\"tp\"]\n",
    "da_timeseries = xr.concat(\n",
    "    [\n",
    "        da_eobs.expand_dims(product=[\"E-OBS\"]),\n",
    "        (da_era5 * 1.0e3).expand_dims(product=[\"ERA5\"]),\n",
    "    ],\n",
    "    \"product\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Define useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_statistics_dataframe(da):\n",
    "    dims = set(da.dims) - {\"period\"}\n",
    "    return pd.DataFrame.from_dict(\n",
    "        {\n",
    "            \"period\": da[\"period\"],\n",
    "            \"number\": da.notnull().sum(dims),\n",
    "            \"mean\": da.mean(dims),\n",
    "            \"maximum\": da.max(dims),\n",
    "            \"minimum\": da.min(dims),\n",
    "            \"st.deviation\": da.std(dims),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_hist(da, **kwargs):\n",
    "    hist, bin_edges = np.histogram(da, **kwargs)\n",
    "    da_hist = xr.DataArray(hist, coords={\"bins\": (bin_edges[1:] + bin_edges[:-1]) / 2})\n",
    "    da_hist[\"bins\"].attrs = da.attrs\n",
    "    da_hist.attrs[\"long_name\"] = \"Probability Density\"\n",
    "    return da_hist\n",
    "\n",
    "\n",
    "def plot_pdf(da, colors, bins=None, **kwargs):\n",
    "    if bins is None:\n",
    "        bins = np.linspace(da.min().values, da.max().values, 50)\n",
    "\n",
    "    dims = []\n",
    "    for key in {\"hue\", \"row\", \"col\"} & set(kwargs):\n",
    "        dims.append(kwargs[key])\n",
    "    da = da.groupby(dims).map(compute_hist, bins=bins, density=True)\n",
    "    with plt.rc_context(\n",
    "        {\n",
    "            \"axes.prop_cycle\": plt.cycler(color=colors),\n",
    "            \"axes.grid\": True,\n",
    "        }\n",
    "    ):\n",
    "        return da.plot(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Show Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_statistics_dataframe(ds_periods[\"mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_statistics_dataframe(ds_periods[\"spread\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Compare timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_timeseries.plot(hue=\"product\")\n",
    "plt.title(\"Comparison\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_timeseries_yearly = da_timeseries.sel(product=\"E-OBS\").groupby(\"time.year\").mean()\n",
    "zooms = {\n",
    "    \"maximum\": int(da_timeseries_yearly.idxmax(\"year\").squeeze()),\n",
    "    \"minimum\": int(da_timeseries_yearly.idxmin(\"year\").squeeze()),\n",
    "}\n",
    "for label, year in zooms.items():\n",
    "    da = da_timeseries.sel(time=str(year))\n",
    "    da.plot(hue=\"product\")\n",
    "    plt.grid()\n",
    "    plt.title(f\"The year with the {label} is {year}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Plot each period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps_kwargs = {\"col\": \"period\", \"cmap\": \"jet\", \"robust\": True}\n",
    "pdf_kwargs = {\"colors\": colors, \"hue\": \"period\", \"figsize\": [15, 5]}\n",
    "for da in ds_periods.data_vars.values():\n",
    "    plot.projected_map(da.mean(\"dayofyear\", keep_attrs=True), **maps_kwargs)\n",
    "    plt.show()\n",
    "\n",
    "    plot_pdf(da, **pdf_kwargs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Plot maps for each season and period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for da in ds_periods.data_vars.values():\n",
    "    plot.projected_map(\n",
    "        da.groupby(\"season\").mean(keep_attrs=True),\n",
    "        row=\"season\",\n",
    "        **maps_kwargs,\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    plot_pdf(da, col=\"season\", **pdf_kwargs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Plot bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (da_timeseries > 10).groupby(\"time.year\").sum().to_pandas()\n",
    "axes = df.T.plot.bar(figsize=[15, 5], subplots=True)\n",
    "for ax, (product, df_product) in zip(axes, df.groupby(\"product\")):\n",
    "    years = df_product.columns\n",
    "    x_values = years - years[0]\n",
    "    mk_result = mk.original_test(df_product.squeeze().values)\n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(\n",
    "        x_values,\n",
    "        df_product.squeeze(),\n",
    "    )\n",
    "    ax.plot(x_values, intercept + slope * (x_values), \"k--\", label=\"Sen's Slope\")\n",
    "    text = \"\\n\".join(\n",
    "        [\n",
    "            f\"Slope: {slope:.4f} days/year\",\n",
    "            f\"P-value: {p_value:.4f}\",\n",
    "            f\"Tau: {mk_result.Tau:.4f}\",\n",
    "            f\"Intercept: {intercept:.4f} days\",\n",
    "        ]\n",
    "    )\n",
    "    ax.text(1.01, 1, text, transform=ax.transAxes, fontsize=10, ha=\"left\", va=\"top\")\n",
    "    ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
