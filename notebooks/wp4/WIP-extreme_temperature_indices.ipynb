{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP: Extreme temperature indices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import icclim\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from c3s_eqc_automatic_quality_control import diagnostics, download, plot\n",
    "from xarrayMannKendall import Mann_Kendall_test\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-notebook\")\n",
    "plt.rcParams[\"hatch.linewidth\"] = 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Time period\n",
    "year_start = 1971\n",
    "year_stop = 2005\n",
    "\n",
    "# Choose annual or seasonal timeseries\n",
    "timeseries = \"JJA\"\n",
    "assert timeseries in (\"annual\", \"DJF\", \"MAM\", \"JJA\", \"SON\")\n",
    "\n",
    "# Choose CORDEX or CMIP6\n",
    "collection_id = \"CMIP6\"\n",
    "assert collection_id in (\"CORDEX\", \"CMIP6\")\n",
    "\n",
    "# Define region for analysis\n",
    "area = [72, -22, 27, 45]\n",
    "\n",
    "# Define region for request\n",
    "cordex_domain = \"europe\"\n",
    "\n",
    "# Define index names\n",
    "index_names = (\"SU\", \"TX90p\")\n",
    "\n",
    "# Interpolation method\n",
    "interpolation_method = \"bilinear\"\n",
    "\n",
    "# Chunks for download\n",
    "chunks = {\"year\": 1}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_cordex = [\n",
    "    \"clmcom_eth_cosmo_crclim\",\n",
    "    \"dmi_hirham5\",\n",
    "    \"knmi_racmo22e\",\n",
    "    \"mpi_csc_remo2009\",\n",
    "    \"uhoh_wrf361h\",\n",
    "]\n",
    "\n",
    "models_cmip6 = [\n",
    "    \"EC-Earth3-CC\",\n",
    "    \"mpi_esm1_2_lr\",\n",
    "    \"access_cm2\",\n",
    "    \"awi_esm_1_1_lr\",\n",
    "    \"cnrm_cm6_1\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ERA5 request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_era = (\n",
    "    \"reanalysis-era5-single-levels\",\n",
    "    {\n",
    "        \"product_type\": \"reanalysis\",\n",
    "        \"format\": \"netcdf\",\n",
    "        \"time\": [f\"{hour:02d}:00\" for hour in range(24)],\n",
    "        \"variable\": \"2m_temperature\",\n",
    "        \"year\": [\n",
    "            str(year) for year in range(year_start - 1, year_stop + 1)\n",
    "        ],  # Include D(year-1)\n",
    "        \"month\": [f\"{month:02d}\" for month in range(1, 13)],\n",
    "        \"day\": [f\"{day:02d}\" for day in range(1, 32)],\n",
    "        \"area\": area,\n",
    "    },\n",
    ")\n",
    "\n",
    "request_lsm = (\n",
    "    request_era[0],\n",
    "    request_era[1]\n",
    "    | {\n",
    "        \"year\": \"1940\",\n",
    "        \"month\": \"01\",\n",
    "        \"day\": \"01\",\n",
    "        \"time\": \"00:00\",\n",
    "        \"variable\": \"land_sea_mask\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# TODO\n",
    "request_cordex = {\n",
    "    \"format\": \"zip\",\n",
    "    \"domain\": cordex_domain,\n",
    "    \"experiment\": \"historical\",\n",
    "    \"horizontal_resolution\": \"0_11_degree_x_0_11_degree\",\n",
    "    \"temporal_resolution\": \"monthly_mean\",\n",
    "    \"variable\": \"daily_maximum_near_surface_air_temperature\",\n",
    "    \"gcm_model\": \"mpi_m_mpi_esm_lr\",\n",
    "    \"ensemble_member\": \"r1i1p1\",\n",
    "    \"area\": area,\n",
    "}\n",
    "###################################################\n",
    "\n",
    "request_cmip6 = {\n",
    "    \"format\": \"zip\",\n",
    "    \"temporal_resolution\": \"daily\",\n",
    "    \"experiment\": \"historical\",\n",
    "    \"variable\": \"daily_maximum_near_surface_air_temperature\",\n",
    "    \"year\": [\n",
    "        str(year) for year in range(year_start - 1, year_stop + 1)\n",
    "    ],  # Include D(year-1)\n",
    "    \"month\": [f\"{month:02d}\" for month in range(1, 13)],\n",
    "    \"day\": [f\"{day:02d}\" for day in range(1, 32)],\n",
    "    \"area\": area,\n",
    "}\n",
    "\n",
    "\n",
    "def get_cordex_years(\n",
    "    year_start,\n",
    "    year_stop,\n",
    "    start_years=[1971, 1981, 1991, 2001],\n",
    "    end_years=[1980, 1990, 2000, 2005],\n",
    "):\n",
    "    start_year = []\n",
    "    end_year = []\n",
    "    years = set(range(year_start - 1, year_stop + 1))  # Include D(year-1)\n",
    "    for start, end in zip(start_years, end_years):\n",
    "        if years & set(range(start, end + 1)):\n",
    "            start_year.append(start)\n",
    "            end_year.append(end)\n",
    "    return start_year, end_year\n",
    "\n",
    "\n",
    "if collection_id == \"CORDEX\":\n",
    "    raise NotImplementedError(f\"{collection_id=}\")\n",
    "    models = models_cordex\n",
    "    model_key = \"rcm_model\"\n",
    "    request_sim = (\n",
    "        \"projections-cordex-domains-single-levels\",\n",
    "        [\n",
    "            {\n",
    "                **request_cordex,\n",
    "                \"start_year\": start_year,\n",
    "                \"end_year\": end_year,\n",
    "            }\n",
    "            for start_year, end_year in zip(*get_cordex_years(year_start, year_stop))\n",
    "        ],\n",
    "    )\n",
    "elif collection_id == \"CMIP6\":\n",
    "    models = models_cmip6\n",
    "    model_key = \"model\"\n",
    "    request_sim = (\n",
    "        \"projections-cmip6\",\n",
    "        download.split_request(request_cmip6, chunks=chunks),\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"{collection_id=}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_timeseries(ds, timeseries, year_start, year_stop):\n",
    "    if timeseries == \"annual\":\n",
    "        return ds.sel(time=slice(str(year_start), str(year_stop)))\n",
    "    ds = ds.sel(time=slice(f\"{year_start-1}-12\", f\"{year_stop}-11\"))\n",
    "    return ds.where(ds[\"time\"].dt.season == timeseries, drop=True)\n",
    "\n",
    "\n",
    "def compute_indices(ds, index_names, timeseries, tmpdir):\n",
    "    years, datasets = zip(*ds.groupby(\"time.year\"))\n",
    "    paths = [f\"{tmpdir}/{year}.nc\" for year in years]\n",
    "    datasets = [ds.chunk(-1) for ds in datasets]\n",
    "    xr.save_mfdataset(datasets, paths)\n",
    "\n",
    "    datasets = [\n",
    "        icclim.index(\n",
    "            index_name=index_name,\n",
    "            in_files=paths,\n",
    "            out_file=f\"{tmpdir}/{index_name}.nc\",\n",
    "            slice_mode=\"year\" if timeseries == \"annual\" else timeseries,\n",
    "        )\n",
    "        for index_name in index_names\n",
    "    ]\n",
    "    return xr.merge(datasets).drop_dims(\"bounds\")\n",
    "\n",
    "\n",
    "def compute_trends(ds):\n",
    "    datasets = []\n",
    "    coords_name = {\"time\": \"time\", \"y\": \"latitude\", \"x\": \"longitude\"}\n",
    "    for index, da in ds.data_vars.items():\n",
    "        ds = Mann_Kendall_test(\n",
    "            da - da.mean(\"time\"),\n",
    "            alpha=0.05,\n",
    "            method=\"theilslopes\",\n",
    "            coords_name=coords_name,\n",
    "        ).compute()\n",
    "        ds = ds.rename({k: v for k, v in coords_name.items() if k in ds.dims})\n",
    "        ds = ds.assign_coords({dim: da[dim] for dim in ds.dims})\n",
    "        datasets.append(ds.expand_dims(index=[index]))\n",
    "    ds = xr.concat(datasets, \"index\")\n",
    "    return ds\n",
    "\n",
    "\n",
    "def compute_indices_and_trends(\n",
    "    ds,\n",
    "    index_names,\n",
    "    timeseries,\n",
    "    year_start,\n",
    "    year_stop,\n",
    "    resample,\n",
    "    **regrid_kwargs,\n",
    "):\n",
    "    if regrid_kwargs.get(\"method\") == \"conservative\":\n",
    "        bounds = [\n",
    "            ds.cf.get_bounds(coord).reset_coords(drop=True)\n",
    "            for coord in (\"latitude\", \"longitude\")\n",
    "            if coord in ds.cf.bounds\n",
    "        ]\n",
    "    else:\n",
    "        bounds = []\n",
    "\n",
    "    ds = select_timeseries(ds, timeseries, year_start, year_stop)\n",
    "    if resample:\n",
    "        ds = ds.resample(time=\"1D\").max(keep_attrs=True)\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        ds_indices = compute_indices(ds, index_names, timeseries, tmpdir).persist()\n",
    "        ds_trends = compute_trends(ds_indices)\n",
    "        ds = ds_indices.mean(\"time\", keep_attrs=True)\n",
    "        ds = ds.merge(ds_trends)\n",
    "        if regrid_kwargs:\n",
    "            ds = diagnostics.regrid(\n",
    "                ds.merge({da.name: da for da in bounds}),\n",
    "                **regrid_kwargs,\n",
    "            )\n",
    "        return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and transform ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_func_kwargs = {\n",
    "    \"index_names\": sorted(index_names),\n",
    "    \"timeseries\": timeseries,\n",
    "    \"year_start\": year_start,\n",
    "    \"year_stop\": year_stop,\n",
    "}\n",
    "ds_era5 = download.download_and_transform(\n",
    "    *request_era,\n",
    "    chunks=chunks,\n",
    "    transform_chunks=False,\n",
    "    transform_func=compute_indices_and_trends,\n",
    "    transform_func_kwargs=transform_func_kwargs | {\"resample\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and transform model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_out = ds_era5[[\"latitude\", \"longitude\"]].reset_coords(drop=True)\n",
    "grid_out.attrs = {}\n",
    "\n",
    "model_datasets = {}\n",
    "interpolated_datasets = []\n",
    "for model in models:\n",
    "    print(f\"{model=}\")\n",
    "    requests = request_sim[1]\n",
    "    # Original grid\n",
    "    model_datasets[model] = download.download_and_transform(\n",
    "        request_sim[0],\n",
    "        [request | {model_key: model} for request in requests],\n",
    "        chunks=chunks,\n",
    "        transform_chunks=False,\n",
    "        transform_func=compute_indices_and_trends,\n",
    "        transform_func_kwargs=transform_func_kwargs | {\"resample\": False},\n",
    "    )\n",
    "    # Interpolated\n",
    "    ds = download.download_and_transform(\n",
    "        request_sim[0],\n",
    "        [request | {model_key: model} for request in requests],\n",
    "        chunks=chunks,\n",
    "        transform_chunks=False,\n",
    "        transform_func=compute_indices_and_trends,\n",
    "        transform_func_kwargs=transform_func_kwargs\n",
    "        | {\"resample\": False, \"grid_out\": grid_out, \"method\": interpolation_method},\n",
    "    )\n",
    "    interpolated_datasets.append(ds.expand_dims(model=[model]))\n",
    "\n",
    "ds_models = xr.concat(interpolated_datasets, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_maps(ds_era5, ds_models, index, trend, model, model_datasets={}, **kwargs):\n",
    "    is_ensemble = model.lower() == \"ensemble\"\n",
    "\n",
    "    # Hide interpolated edges\n",
    "    isel_dict = {coord: slice(5, -5) for coord in (\"latitude\", \"longitude\")}\n",
    "    ds_era5 = ds_era5.isel(isel_dict).sel(index=index)\n",
    "    ds_models = ds_models.isel(isel_dict).sel(index=index)\n",
    "\n",
    "    if is_ensemble:\n",
    "        median = ds_models.median(\"model\", keep_attrs=True)\n",
    "        with xr.set_options(keep_attrs=True):\n",
    "            bias = median - ds_era5\n",
    "        std = ds_models.std(\"model\", keep_attrs=True)\n",
    "        datasets = {\n",
    "            \"ERA5\": ds_era5,\n",
    "            \"Ensemble Median\": median,\n",
    "            \"Ensemble Median Bias\": bias,\n",
    "            \"Ensemble Standard Deviation\": std,\n",
    "        }\n",
    "    else:\n",
    "        ds_model = model_datasets[model].sel(index=index)\n",
    "        with xr.set_options(keep_attrs=True):\n",
    "            bias = ds_models.sel(model=model) - ds_era5\n",
    "        datasets = {\n",
    "            \"ERA5\": ds_era5,\n",
    "            model: ds_model,\n",
    "            f\"{model} Bias\": bias,\n",
    "        }\n",
    "\n",
    "    # Initialize figure\n",
    "    fig, axes = plt.subplots(\n",
    "        *(2, 2),\n",
    "        subplot_kw={\"projection\": ccrs.PlateCarree()},\n",
    "        figsize=(14, 7),\n",
    "    )\n",
    "    for i, (ax, ds) in enumerate(zip(axes.flatten(), datasets.values())):\n",
    "        da = ds[\"trend\" if trend else index]\n",
    "        if trend:\n",
    "            da *= 10\n",
    "            da.attrs[\"units\"] = \"days / decade\"\n",
    "        plot_kwargs = kwargs if i <= 1 else {\"robust\": True}\n",
    "        plot.projected_map(da, show_stats=False, ax=ax, **plot_kwargs)\n",
    "\n",
    "    if trend:\n",
    "        hatches_kwargs = {\n",
    "            \"plot_func\": \"contourf\",\n",
    "            \"show_stats\": False,\n",
    "            \"cmap\": \"none\",\n",
    "            \"add_colorbar\": False,\n",
    "        }\n",
    "        plot.projected_map(\n",
    "            ds_era5[\"p\"],\n",
    "            ax=axes[0, 0],\n",
    "            levels=[0, 0.05, 1],\n",
    "            hatches=[\"\", \"/\" * 3],\n",
    "            **hatches_kwargs,\n",
    "        )\n",
    "        if is_ensemble:\n",
    "            n_models = ds_models.sizes[\"model\"]\n",
    "            robust_ratio = (ds_models[\"p\"] <= 0.05).sum(\"model\") / n_models\n",
    "            robust_ratio = robust_ratio.where(ds_models[\"p\"].notnull().any(\"model\"))\n",
    "            sign_ratio = (\n",
    "                xr.concat(\n",
    "                    [\n",
    "                        (ds_models[\"trend\"] > 0).sum(\"model\"),\n",
    "                        (ds_models[\"trend\"] < 0).sum(\"model\"),\n",
    "                    ],\n",
    "                    \"sign\",\n",
    "                ).max(\"sign\")\n",
    "                / n_models\n",
    "            )\n",
    "            robust_threshold = 0.66\n",
    "            sign_ratio = sign_ratio.where(robust_ratio > robust_threshold)\n",
    "            for da, threshold, character in zip(\n",
    "                [robust_ratio, sign_ratio], [robust_threshold, 0.8], [\"\\\\\", \"/\"]\n",
    "            ):\n",
    "                plot.projected_map(\n",
    "                    da,\n",
    "                    ax=axes[0, 1],\n",
    "                    levels=[0, threshold, 1],\n",
    "                    hatches=[character * 3, \"\"],\n",
    "                    **hatches_kwargs,\n",
    "                )\n",
    "        else:\n",
    "            plot.projected_map(\n",
    "                ds_model[\"p\"],\n",
    "                ax=axes[0, 1],\n",
    "                levels=[0, 0.05, 1],\n",
    "                hatches=[\"\", \"/\" * 3],\n",
    "                **hatches_kwargs,\n",
    "            )\n",
    "    for ax, title in zip(axes.flatten(), datasets.keys()):\n",
    "        ax.set_title(title)\n",
    "    fig.suptitle(f\"Trend of {index}\" if trend else index)\n",
    "    plt.axis(\"off\")\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask land\n",
    "lsm = download.download_and_transform(*request_lsm)[\"lsm\"].squeeze(drop=True)\n",
    "ds_era5 = ds_era5.where(lsm)\n",
    "ds_models = ds_models.where(lsm)\n",
    "model_datasets = {\n",
    "    model: ds.where(diagnostics.regrid(lsm, ds, method=\"bilinear\"))\n",
    "    for model, ds in model_datasets.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define cbar limits\n",
    "index_kwargs = {\n",
    "    \"SU\": {\"vmin\": 10, \"vmax\": 80},\n",
    "    \"TX90p\": {\"vmin\": 8, \"vmax\": 9},\n",
    "}\n",
    "trend_kwargs = {\n",
    "    \"SU\": {\"vmin\": -8, \"center\": 0},\n",
    "    \"TX90p\": {\"vmin\": -6, \"center\": 0},\n",
    "}\n",
    "for index in index_names:\n",
    "    for trend in (False, True):\n",
    "        kwargs = (trend_kwargs if trend else index_kwargs)[index]\n",
    "        kwargs = kwargs | {\"extend\": \"both\"}\n",
    "        fig, axes = plot_maps(\n",
    "            ds_era5,\n",
    "            ds_models,\n",
    "            index=index,\n",
    "            trend=trend,\n",
    "            model=\"ensemble\",\n",
    "            **kwargs,\n",
    "        )\n",
    "        plt.show()\n",
    "        for model in model_datasets:\n",
    "            fig, axes = plot_maps(\n",
    "                ds_era5,\n",
    "                ds_models,\n",
    "                index=index,\n",
    "                trend=trend,\n",
    "                model=model,\n",
    "                model_datasets=model_datasets,\n",
    "                **kwargs,\n",
    "            )\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in index_names:\n",
    "    # Models\n",
    "    da = ds_models[\"trend\"].sel(index=index)\n",
    "    da = diagnostics.spatial_weighted_mean(da) * 10\n",
    "    df_slope = da.to_dataframe()[[\"trend\"]]\n",
    "    ax = df_slope.boxplot()\n",
    "    ax.scatter(\n",
    "        x=[1] * len(df_slope),\n",
    "        y=df_slope,\n",
    "        color=\"grey\",\n",
    "        marker=\".\",\n",
    "        label=\"models\",\n",
    "    )\n",
    "\n",
    "    # ERA5\n",
    "    da = ds_era5[\"trend\"].sel(index=index)\n",
    "    da = diagnostics.spatial_weighted_mean(da) * 10\n",
    "    ax.scatter(\n",
    "        x=2,\n",
    "        y=da.values,\n",
    "        color=\"orange\",\n",
    "        marker=\"o\",\n",
    "        label=\"ERA5\",\n",
    "    )\n",
    "\n",
    "    # Figure settings\n",
    "    ax.set_xticks([1, 2], [f\"{collection_id} Ensemble\", \"ERA5\"])\n",
    "    ax.set_ylabel(\"days / decade\")\n",
    "    plt.suptitle(f\"Trend of {index}\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
