{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Extreme temperature indices: Historical VS Future"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import tempfile\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import icclim\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from c3s_eqc_automatic_quality_control import diagnostics, download, plot\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-notebook\")\n",
    "plt.rcParams[\"hatch.linewidth\"] = 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Time period historical\n",
    "year_start_historical = 1971\n",
    "year_stop_historical = 2000\n",
    "\n",
    "# Models time post\n",
    "models = {\n",
    "    \"access_cm2\": slice(2023, 2052),\n",
    "    \"awi_cm_1_1_mr\": slice(2022, 2051),\n",
    "    \"canesm5\": slice(2015, 2044),\n",
    "    \"cmcc_esm2\": slice(2024, 2053),\n",
    "    \"cnrm_cm6_1_hr\": slice(2016, 2045),\n",
    "    \"ec_earth3_cc\": slice(2020, 2049),\n",
    "    \"gfdl_esm4\": slice(2038, 2067),\n",
    "    \"miroc6\": slice(2039, 2068),\n",
    "    \"mpi_esm1_2_lr\": slice(2034, 2063),\n",
    "}\n",
    "assert all(year_slice.start > year_stop_historical for year_slice in models.values())\n",
    "\n",
    "# Choose model for regridding\n",
    "model_regrid = \"gfdl_esm4\"\n",
    "\n",
    "# Choose annual or seasonal timeseries\n",
    "timeseries = \"JJA\"\n",
    "assert timeseries in (\"annual\", \"DJF\", \"MAM\", \"JJA\", \"SON\")\n",
    "\n",
    "# Define region for analysis\n",
    "area = [72, -22, 27, 45]\n",
    "\n",
    "# Define region for request\n",
    "cordex_domain = \"europe\"\n",
    "\n",
    "# Define index names\n",
    "index_names = (\"SU\", \"TX90p\")\n",
    "\n",
    "# Interpolation method\n",
    "interpolation_method = \"bilinear\"\n",
    "\n",
    "# Chunks for download\n",
    "chunks = {\"year\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define lsm request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_lsm = (\n",
    "    \"reanalysis-era5-single-levels\",\n",
    "    {\n",
    "        \"product_type\": \"reanalysis\",\n",
    "        \"format\": \"netcdf\",\n",
    "        \"time\": \"00:00\",\n",
    "        \"variable\": \"land_sea_mask\",\n",
    "        \"year\": \"1940\",\n",
    "        \"month\": \"01\",\n",
    "        \"day\": \"01\",\n",
    "        \"area\": area,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_years(year_start, year_stop, timeseries):\n",
    "    return [\n",
    "        str(year)\n",
    "        for year in range(year_start - int(timeseries == \"DJF\"), year_stop + 1)\n",
    "    ]\n",
    "\n",
    "\n",
    "collection_id = \"projections-cmip6\"\n",
    "\n",
    "request = {\n",
    "    \"format\": \"zip\",\n",
    "    \"temporal_resolution\": \"daily\",\n",
    "    \"variable\": \"daily_maximum_near_surface_air_temperature\",\n",
    "    \"month\": [f\"{month:02d}\" for month in range(1, 13)],\n",
    "    \"day\": [f\"{day:02d}\" for day in range(1, 32)],\n",
    "    \"area\": area,\n",
    "}\n",
    "\n",
    "request_historical = request | {\n",
    "    \"year\": get_years(year_start_historical, year_stop_historical, timeseries),\n",
    "    \"experiment\": \"historical\",\n",
    "}\n",
    "request_future = request | {\n",
    "    \"experiment\": \"ssp5_8_5\",\n",
    "}\n",
    "\n",
    "model_requests = {}\n",
    "for model, year_slice in models.items():\n",
    "    years_future = get_years(year_slice.start, year_slice.stop, timeseries)\n",
    "    model_request_historical = download.split_request(\n",
    "        request_historical | {\"model\": model}, chunks=chunks\n",
    "    )\n",
    "    model_request_future = download.split_request(\n",
    "        request_future | {\"model\": model, \"year\": years_future}, chunks=chunks\n",
    "    )\n",
    "    model_requests[model] = model_request_historical + model_request_future\n",
    "\n",
    "request_grid_out = model_requests[model_regrid]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def separate_historical_and_future(ds, year_stop_historical):\n",
    "    return [ds for _, ds in ds.groupby(ds[\"time\"].dt.year <= year_stop_historical)]\n",
    "\n",
    "\n",
    "def select_timeseries(ds, timeseries, year_stop_historical):\n",
    "    datasets = []\n",
    "    for ds in separate_historical_and_future(ds, year_stop_historical):\n",
    "        if timeseries == \"DJF\":\n",
    "            year_start = ds[\"time\"].dt.year.min().values\n",
    "            year_stop = ds[\"time\"].dt.year.max().values\n",
    "            ds = ds.sel(time=slice(f\"{year_start}-12\", f\"{year_stop}-11\"))\n",
    "        datasets.append(ds)\n",
    "    ds = xr.concat(datasets, \"time\")\n",
    "    if timeseries == \"annual\":\n",
    "        return ds\n",
    "    return ds.where(ds[\"time\"].dt.season == timeseries, drop=True)\n",
    "\n",
    "\n",
    "def compute_indices(ds, index_names, timeseries, tmpdir, year_stop_historical):\n",
    "    labels, datasets = zip(*ds.groupby(\"time.year\"))\n",
    "    paths = [f\"{tmpdir}/{label}.nc\" for label in labels]\n",
    "    datasets = [ds.chunk(-1) for ds in datasets]\n",
    "    xr.save_mfdataset(datasets, paths)\n",
    "\n",
    "    ds = xr.open_mfdataset(paths)\n",
    "    in_files = f\"{tmpdir}/rechunked.zarr\"\n",
    "    chunks = {dim: -1 if dim == \"time\" else \"auto\" for dim in ds.dims}\n",
    "    ds.chunk(chunks).to_zarr(in_files)\n",
    "\n",
    "    start = str(ds[\"time\"].min().values)\n",
    "    stop = str(ds[\"time\"].max().values)\n",
    "    historical_range = (start, f\"{year_stop_historical}-12-31\")\n",
    "    future_range = (f\"{year_stop_historical+1}-01-01\", stop)\n",
    "\n",
    "    datasets = []\n",
    "    for index_name in index_names:\n",
    "        kwargs = {\n",
    "            \"index_name\": index_name,\n",
    "            \"in_files\": in_files,\n",
    "            \"slice_mode\": \"year\" if timeseries == \"annual\" else timeseries,\n",
    "        }\n",
    "        if index_name == \"TX90p\":\n",
    "            datasets.append(\n",
    "                icclim.index(\n",
    "                    out_file=f\"{tmpdir}/{index_name}.nc\",\n",
    "                    time_range=future_range,\n",
    "                    base_period_time_range=historical_range,\n",
    "                    **kwargs,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            ds_historical = icclim.index(\n",
    "                out_file=f\"{tmpdir}/{index_name}_historical.nc\",\n",
    "                time_range=historical_range,\n",
    "                **kwargs,\n",
    "            )\n",
    "            ds_future = icclim.index(\n",
    "                out_file=f\"{tmpdir}/{index_name}_future.nc\",\n",
    "                time_range=future_range,\n",
    "                **kwargs,\n",
    "            )\n",
    "            with xr.set_options(keep_attrs=True):\n",
    "                datasets.append(ds_future.mean(\"time\") - ds_historical.mean(\"time\"))\n",
    "    return xr.merge(datasets).drop_dims(\"bounds\")\n",
    "\n",
    "\n",
    "def add_bounds(ds):\n",
    "    for coord in {\"latitude\", \"longitude\"} - set(ds.cf.bounds):\n",
    "        ds = ds.cf.add_bounds(coord)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def get_grid_out(request_grid_out, method):\n",
    "    ds_regrid = download.download_and_transform(*request_grid_out)\n",
    "    coords = [\"latitude\", \"longitude\"]\n",
    "    if method == \"conservative\":\n",
    "        ds_regrid = add_bounds(ds_regrid)\n",
    "        for coord in list(coords):\n",
    "            coords.extend(ds_regrid.cf.bounds[coord])\n",
    "    grid_out = ds_regrid[coords]\n",
    "    coords_to_drop = set(grid_out.coords) - set(coords) - set(grid_out.dims)\n",
    "    grid_out = ds_regrid[coords].reset_coords(coords_to_drop, drop=True)\n",
    "    grid_out.attrs = {}\n",
    "    return grid_out\n",
    "\n",
    "\n",
    "def compute_indices_and_trends_historical_vs_future(\n",
    "    ds,\n",
    "    index_names,\n",
    "    timeseries,\n",
    "    year_stop_historical,\n",
    "    resample,\n",
    "    request_grid_out=None,\n",
    "    **regrid_kwargs,\n",
    "):\n",
    "    assert (request_grid_out and regrid_kwargs) or not (\n",
    "        request_grid_out or regrid_kwargs\n",
    "    )\n",
    "    ds = ds.drop_vars([var for var, da in ds.data_vars.items() if len(da.dims) != 3])\n",
    "    ds = ds[list(ds.data_vars)]\n",
    "\n",
    "    # Original bounds for conservative interpolation\n",
    "    if regrid_kwargs.get(\"method\") == \"conservative\":\n",
    "        ds = add_bounds(ds)\n",
    "        bounds = [\n",
    "            ds.cf.get_bounds(coord).reset_coords(drop=True)\n",
    "            for coord in (\"latitude\", \"longitude\")\n",
    "        ]\n",
    "    else:\n",
    "        bounds = []\n",
    "\n",
    "    ds = select_timeseries(ds, timeseries, year_stop_historical)\n",
    "    if resample:\n",
    "        ds = ds.resample(time=\"1D\").max(keep_attrs=True)\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        ds_indices = compute_indices(\n",
    "            ds, index_names, timeseries, tmpdir, year_stop_historical\n",
    "        ).compute()\n",
    "        ds = ds_indices.mean(\"time\", keep_attrs=True)\n",
    "        if request_grid_out:\n",
    "            ds = diagnostics.regrid(\n",
    "                ds.merge({da.name: da for da in bounds}),\n",
    "                grid_out=get_grid_out(request_grid_out, regrid_kwargs[\"method\"]),\n",
    "                **regrid_kwargs,\n",
    "            )\n",
    "        return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Download and transform regrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"collection_id\": collection_id,\n",
    "    \"chunks\": chunks,\n",
    "    \"transform_chunks\": False,\n",
    "    \"transform_func\": compute_indices_and_trends_historical_vs_future,\n",
    "}\n",
    "transform_func_kwargs = {\n",
    "    \"index_names\": sorted(index_names),\n",
    "    \"timeseries\": timeseries,\n",
    "    \"year_stop_historical\": year_stop_historical,\n",
    "    \"resample\": False,\n",
    "}\n",
    "ds_regrid = download.download_and_transform(\n",
    "    requests=request_grid_out,\n",
    "    **kwargs,\n",
    "    transform_func_kwargs=transform_func_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and transform models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "interpolated_datasets = []\n",
    "model_datasets = {}\n",
    "for model, requests in model_requests.items():\n",
    "    print(f\"{model=}\")\n",
    "    # Original model\n",
    "    ds = download.download_and_transform(\n",
    "        requests=requests,\n",
    "        **kwargs,\n",
    "        transform_func_kwargs=transform_func_kwargs,\n",
    "    )\n",
    "    model_datasets[model] = ds\n",
    "\n",
    "    if model != model_regrid:\n",
    "        # Interpolated model\n",
    "        ds = download.download_and_transform(\n",
    "            requests=requests,\n",
    "            **kwargs,\n",
    "            transform_func_kwargs=transform_func_kwargs\n",
    "            | {\n",
    "                \"request_grid_out\": (collection_id, request_grid_out),\n",
    "                \"method\": interpolation_method,\n",
    "                \"skipna\": True,\n",
    "            },\n",
    "        )\n",
    "    interpolated_datasets.append(ds.expand_dims(model=[model]))\n",
    "\n",
    "ds_interpolated = xr.concat(interpolated_datasets, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask land and change attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask\n",
    "lsm = download.download_and_transform(*request_lsm)[\"lsm\"].squeeze(drop=True)\n",
    "ds_interpolated = ds_interpolated.where(\n",
    "    diagnostics.regrid(lsm, ds_interpolated, method=\"bilinear\")\n",
    ")\n",
    "model_datasets = {\n",
    "    model: ds.where(diagnostics.regrid(lsm, ds, method=\"bilinear\"))\n",
    "    for model, ds in model_datasets.items()\n",
    "}\n",
    "\n",
    "# Edit attributes\n",
    "for ds in (ds_interpolated, *model_datasets.values()):\n",
    "    for index in index_names:\n",
    "        ds[index].attrs = {\"long_name\": \"\", \"units\": \"days\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hatch_p_value(da, ax, **kwargs):\n",
    "    default_kwargs = {\n",
    "        \"plot_func\": \"contourf\",\n",
    "        \"show_stats\": False,\n",
    "        \"cmap\": \"none\",\n",
    "        \"add_colorbar\": False,\n",
    "        \"levels\": [0, 0.05, 1],\n",
    "        \"hatches\": [\"\", \"/\" * 3],\n",
    "    }\n",
    "    kwargs = default_kwargs | kwargs\n",
    "\n",
    "    title = ax.get_title()\n",
    "    plot_obj = plot.projected_map(da, ax=ax, **kwargs)\n",
    "    ax.set_title(title)\n",
    "    return plot_obj\n",
    "\n",
    "\n",
    "def hatch_p_value_ensemble(trend, p_value, ax):\n",
    "    n_models = trend.sizes[\"model\"]\n",
    "    robust_ratio = (p_value <= 0.05).sum(\"model\") / n_models\n",
    "    robust_ratio = robust_ratio.where(p_value.notnull().any(\"model\"))\n",
    "    signs = xr.concat([(trend > 0).sum(\"model\"), (trend < 0).sum(\"model\")], \"sign\")\n",
    "    sign_ratio = signs.max(\"sign\") / n_models\n",
    "    robust_threshold = 0.66\n",
    "    sign_ratio = sign_ratio.where(robust_ratio > robust_threshold)\n",
    "    for da, threshold, character in zip(\n",
    "        [robust_ratio, sign_ratio], [robust_threshold, 0.8], [\"/\", \"\\\\\"]\n",
    "    ):\n",
    "        hatch_p_value(da, ax=ax, levels=[0, threshold, 1], hatches=[character * 3, \"\"])\n",
    "\n",
    "\n",
    "def set_extent(da, axs, area):\n",
    "    extent = [area[i] for i in (1, 3, 2, 0)]\n",
    "    for i, coord in enumerate(extent):\n",
    "        extent[i] += -1 if i % 2 else +1\n",
    "    for ax in axs:\n",
    "        ax.set_extent(extent)\n",
    "\n",
    "\n",
    "def plot_models(\n",
    "    data,\n",
    "    da_for_kwargs=None,\n",
    "    p_values=None,\n",
    "    col_wrap=3,\n",
    "    subplot_kw={\"projection\": ccrs.PlateCarree()},\n",
    "    figsize=None,\n",
    "    layout=\"constrained\",\n",
    "    area=area,\n",
    "    **kwargs,\n",
    "):\n",
    "    if isinstance(data, dict):\n",
    "        assert da_for_kwargs is not None\n",
    "        model_dataarrays = data\n",
    "    else:\n",
    "        da_for_kwargs = da_for_kwargs or data\n",
    "        model_dataarrays = dict(data.groupby(\"model\"))\n",
    "\n",
    "    if p_values is not None:\n",
    "        model_p_dataarrays = (\n",
    "            p_values if isinstance(p_values, dict) else dict(p_values.groupby(\"model\"))\n",
    "        )\n",
    "    else:\n",
    "        model_p_dataarrays = None\n",
    "\n",
    "    # Get kwargs\n",
    "    default_kwargs = {\"robust\": True, \"extend\": \"both\"}\n",
    "    kwargs = default_kwargs | kwargs\n",
    "    kwargs = xr.plot.utils._determine_cmap_params(da_for_kwargs.values, **kwargs)\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        *(col_wrap, math.ceil(len(model_dataarrays) / col_wrap)),\n",
    "        subplot_kw=subplot_kw,\n",
    "        figsize=figsize,\n",
    "        layout=layout,\n",
    "    )\n",
    "    axs = axs.flatten()\n",
    "    for (model, da), ax in zip(model_dataarrays.items(), axs):\n",
    "        pcm = plot.projected_map(\n",
    "            da, ax=ax, show_stats=False, add_colorbar=False, **kwargs\n",
    "        )\n",
    "        ax.set_title(model)\n",
    "        if model_p_dataarrays is not None:\n",
    "            hatch_p_value(model_p_dataarrays[model], ax)\n",
    "    set_extent(da_for_kwargs, axs, area)\n",
    "    fig.colorbar(\n",
    "        pcm,\n",
    "        ax=axs.flatten(),\n",
    "        extend=kwargs[\"extend\"],\n",
    "        location=\"right\",\n",
    "        label=f\"{da_for_kwargs.attrs.get('long_name', '')} [{da_for_kwargs.attrs.get('units', '')}]\",\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_ensemble(\n",
    "    da_models,\n",
    "    da_era5=None,\n",
    "    p_value_era5=None,\n",
    "    p_value_models=None,\n",
    "    subplot_kw={\"projection\": ccrs.PlateCarree()},\n",
    "    figsize=None,\n",
    "    layout=\"constrained\",\n",
    "    cbar_kwargs=None,\n",
    "    area=area,\n",
    "    **kwargs,\n",
    "):\n",
    "    # Get kwargs\n",
    "    default_kwargs = {\"robust\": True, \"extend\": \"both\"}\n",
    "    kwargs = default_kwargs | kwargs\n",
    "    kwargs = xr.plot.utils._determine_cmap_params(\n",
    "        da_models.values if da_era5 is None else da_era5.values, **kwargs\n",
    "    )\n",
    "    if da_era5 is None and cbar_kwargs is None:\n",
    "        cbar_kwargs = {\"orientation\": \"horizontal\"}\n",
    "\n",
    "    # Figure\n",
    "    fig, axs = plt.subplots(\n",
    "        *(1 if da_era5 is None else 2, 2),\n",
    "        subplot_kw=subplot_kw,\n",
    "        figsize=figsize,\n",
    "        layout=layout,\n",
    "    )\n",
    "    axs = axs.flatten()\n",
    "    axs_iter = iter(axs)\n",
    "\n",
    "    # ERA5\n",
    "    if da_era5 is not None:\n",
    "        ax = next(axs_iter)\n",
    "        plot.projected_map(\n",
    "            da_era5, ax=ax, show_stats=False, cbar_kwargs=cbar_kwargs, **kwargs\n",
    "        )\n",
    "        if p_value_era5 is not None:\n",
    "            hatch_p_value(p_value_era5, ax=ax)\n",
    "        ax.set_title(\"ERA5\")\n",
    "\n",
    "    # Median\n",
    "    ax = next(axs_iter)\n",
    "    median = da_models.median(\"model\", keep_attrs=True)\n",
    "    plot.projected_map(\n",
    "        median, ax=ax, show_stats=False, cbar_kwargs=cbar_kwargs, **kwargs\n",
    "    )\n",
    "    if p_value_models is not None:\n",
    "        hatch_p_value_ensemble(trend=da_models, p_value=p_value_models, ax=ax)\n",
    "    ax.set_title(\"Ensemble Median\")\n",
    "\n",
    "    # Bias\n",
    "    if da_era5 is not None:\n",
    "        ax = next(axs_iter)\n",
    "        with xr.set_options(keep_attrs=True):\n",
    "            bias = median - da_era5\n",
    "        plot.projected_map(\n",
    "            bias,\n",
    "            ax=ax,\n",
    "            show_stats=False,\n",
    "            center=0,\n",
    "            cbar_kwargs=cbar_kwargs,\n",
    "            **default_kwargs,\n",
    "        )\n",
    "        ax.set_title(\"Ensemble Median Bias\")\n",
    "\n",
    "    # Std\n",
    "    ax = next(axs_iter)\n",
    "    std = da_models.std(\"model\", keep_attrs=True)\n",
    "    plot.projected_map(\n",
    "        std, ax=ax, show_stats=False, cbar_kwargs=cbar_kwargs, **default_kwargs\n",
    "    )\n",
    "    ax.set_title(\"Ensemble Standard Deviation\")\n",
    "\n",
    "    set_extent(da_models, axs, area)\n",
    "    return fig\n",
    "\n",
    "\n",
    "common_title = f\"{year_start_historical=} {year_stop_historical=} {timeseries=}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in index_names:\n",
    "    # Index\n",
    "    fig = plot_ensemble(da_models=ds_interpolated[index])\n",
    "    fig.suptitle(f\"{index}\\n{common_title}\", y=0.8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in index_names:\n",
    "    # Index\n",
    "    fig = plot_models(\n",
    "        data={model: ds[index] for model, ds in model_datasets.items()},\n",
    "        da_for_kwargs=ds_interpolated[index],\n",
    "    )\n",
    "    fig.suptitle(f\"{index}\\n{common_title}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_datasets = [\n",
    "    diagnostics.spatial_weighted_mean(ds.expand_dims(model=[model]), weights=True)\n",
    "    for model, ds in model_datasets.items()\n",
    "]\n",
    "mean_ds = xr.concat(mean_datasets, \"model\")\n",
    "for index, da in mean_ds.data_vars.items():\n",
    "    df_slope = da.to_dataframe()[[index]]\n",
    "    ax = df_slope.boxplot()\n",
    "    ax.scatter(\n",
    "        x=[1] * len(df_slope),\n",
    "        y=df_slope,\n",
    "        color=\"grey\",\n",
    "        marker=\".\",\n",
    "        label=\"models\",\n",
    "    )\n",
    "\n",
    "    # Ensemble mean\n",
    "    ax.scatter(\n",
    "        x=1,\n",
    "        y=da.mean(\"model\"),\n",
    "        marker=\"o\",\n",
    "        label=\"CMIP6 Ensemble Mean\",\n",
    "    )\n",
    "\n",
    "    labels = [\"CMIP6 Ensemble\"]\n",
    "    ax.set_xticks(range(1, len(labels) + 1), labels)\n",
    "    ax.set_ylabel(da.attrs[\"units\"])\n",
    "    plt.suptitle(f\"Trend of {index}\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
