{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precipitation and temperature trends"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skill_metrics\n",
    "import xarray as xr\n",
    "from c3s_eqc_automatic_quality_control import diagnostics, download, plot, utils\n",
    "from xarrayMannKendall import Mann_Kendall_test\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-notebook\")\n",
    "plt.rcParams[\"hatch.linewidth\"] = 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time period\n",
    "year_start = 1971\n",
    "year_stop = 1972\n",
    "\n",
    "# Climatology period\n",
    "clima_year_start = 1971\n",
    "clima_year_stop = 1971\n",
    "\n",
    "# Choose annual or seasonal timeseries\n",
    "timeseries = \"annual\"\n",
    "assert timeseries in (\"annual\", \"DJF\", \"MAM\", \"JJA\", \"SON\")\n",
    "\n",
    "# Variable\n",
    "variable = \"temperature\"\n",
    "assert variable in (\"precipitation\", \"temperature\")\n",
    "\n",
    "# Choose CORDEX or CMIP6\n",
    "collection_id = \"CMIP6\"\n",
    "assert collection_id in (\"CORDEX\", \"CMIP6\")\n",
    "\n",
    "# Define region for analysis\n",
    "lon_slice = slice(-4, 20)\n",
    "lat_slice = slice(35, 50)\n",
    "\n",
    "# Define region for request\n",
    "cordex_domain = \"europe\"\n",
    "\n",
    "# Mask out sea grid nodes\n",
    "mask_sea = True\n",
    "assert isinstance(mask_sea, bool)\n",
    "\n",
    "# Chunks for download\n",
    "chunks = {\"year\": 1}\n",
    "assert \"month\" not in chunks, \"Do not use chunks smaller than 1y\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_cordex = [\n",
    "    \"clmcom_clm_cclm4_8_17\",\n",
    "    \"clmcom_eth_cosmo_crclim\",\n",
    "    \"cnrm_aladin63\",\n",
    "    \"dmi_hirham5\",\n",
    "    \"knmi_racmo22e\",\n",
    "    \"mohc_hadrem3_ga7_05\",\n",
    "    \"mpi_csc_remo2009\",\n",
    "    \"smhi_rca4\",\n",
    "    \"uhoh_wrf361h\",\n",
    "]\n",
    "\n",
    "models_cmip6 = [\n",
    "    \"cmcc_cm2_hr4\",\n",
    "    \"mpi_esm1_2_lr\",\n",
    "    \"access_cm2\",\n",
    "    \"awi_esm_1_1_lr\",\n",
    "    \"bcc_esm1\",\n",
    "    \"cesm2_fv2\",\n",
    "    \"cnrm_cm6_1\",\n",
    "    \"fgoals_g3\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ERA5 request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_variables = {\n",
    "    \"precipitation\": \"mean_total_precipitation_rate\",\n",
    "    \"temperature\": \"2m_temperature\",\n",
    "}\n",
    "\n",
    "request_era = (\n",
    "    \"reanalysis-era5-single-levels-monthly-means\",\n",
    "    {\n",
    "        \"product_type\": \"monthly_averaged_reanalysis\",\n",
    "        \"format\": \"netcdf\",\n",
    "        \"time\": \"00:00\",\n",
    "        \"variable\": era5_variables[variable],\n",
    "        \"year\": [\n",
    "            str(year)\n",
    "            for year in range(\n",
    "                min(year_start, clima_year_start) - 1,  # Include D(year-1)\n",
    "                max(year_stop, clima_year_stop) + 1,\n",
    "            )\n",
    "        ],\n",
    "        \"month\": [f\"{month:02d}\" for month in range(1, 12 + 1)],\n",
    "    },\n",
    ")\n",
    "\n",
    "request_lsm = (\n",
    "    request_era[0],\n",
    "    request_era[1] | {\"year\": \"1940\", \"month\": \"01\", \"variable\": \"land_sea_mask\"},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cordex_variables = {\n",
    "    \"precipitation\": \"mean_precipitation_flux\",\n",
    "    \"temperature\": \"2m_air_temperature\",\n",
    "}\n",
    "\n",
    "request_cordex = {\n",
    "    \"format\": \"zip\",\n",
    "    \"domain\": cordex_domain,\n",
    "    \"experiment\": \"historical\",\n",
    "    \"horizontal_resolution\": \"0_11_degree_x_0_11_degree\",\n",
    "    \"temporal_resolution\": \"monthly_mean\",\n",
    "    \"variable\": cordex_variables[variable],\n",
    "    \"gcm_model\": \"mpi_m_mpi_esm_lr\",\n",
    "    \"ensemble_member\": \"r1i1p1\",\n",
    "}\n",
    "\n",
    "cmip6_variables = {\n",
    "    \"precipitation\": \"precipitation\",\n",
    "    \"temperature\": \"near_surface_air_temperature\",\n",
    "}\n",
    "request_cmip6 = {\n",
    "    \"format\": \"zip\",\n",
    "    \"temporal_resolution\": \"monthly\",\n",
    "    \"experiment\": \"historical\",\n",
    "    \"variable\": cmip6_variables[variable],\n",
    "    \"year\": request_era[1][\"year\"],\n",
    "    \"month\": request_era[1][\"month\"],\n",
    "}\n",
    "\n",
    "\n",
    "def get_cordex_years(\n",
    "    year_start,\n",
    "    year_stop,\n",
    "    start_years=[1971, 1981, 1991, 2001],\n",
    "    end_years=[1980, 1990, 2000, 2005],\n",
    "):\n",
    "    start_year = []\n",
    "    end_year = []\n",
    "    years = set(range(year_start - 1, year_stop + 1))  # Include D(year-1)\n",
    "    for start, end in zip(start_years, end_years):\n",
    "        if years & set(range(start, end + 1)):\n",
    "            start_year.append(start)\n",
    "            end_year.append(end)\n",
    "    return start_year, end_year\n",
    "\n",
    "\n",
    "if collection_id == \"CORDEX\":\n",
    "    weights = False  # Do not weight spatial statistics/errors\n",
    "    periodic = False\n",
    "    models = models_cordex\n",
    "    model_key = \"rcm_model\"\n",
    "    request_sim = (\n",
    "        \"projections-cordex-domains-single-levels\",\n",
    "        [\n",
    "            {\n",
    "                **request_cordex,\n",
    "                \"start_year\": start_year,\n",
    "                \"end_year\": end_year,\n",
    "            }\n",
    "            for start_year, end_year in zip(\n",
    "                *get_cordex_years(\n",
    "                    min(year_start, clima_year_start), max(year_stop, clima_year_stop)\n",
    "                )\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "elif collection_id == \"CMIP6\":\n",
    "    weights = True  # Weight spatial statistics/errors\n",
    "    periodic = True\n",
    "    models = models_cmip6\n",
    "    model_key = \"model\"\n",
    "    request_sim = (\n",
    "        \"projections-cmip6\",\n",
    "        download.split_request(request_cmip6, chunks=chunks),\n",
    "    )\n",
    "else:\n",
    "    raise ValueError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_test = functools.partial(Mann_Kendall_test, alpha=0.05, method=\"theilslopes\")\n",
    "\n",
    "\n",
    "def get_timeseries(ds, year_start, year_stop, timeseries):\n",
    "    # Drop useless data\n",
    "    if timeseries == \"annual\":\n",
    "        mask = (ds[\"time\"].dt.year >= year_start) & (ds[\"time\"].dt.year <= year_stop)\n",
    "    else:\n",
    "        # Select years (shift -1 to get D(year-1)J(year)F(year))\n",
    "        ds = ds.assign_coords(year=ds[\"time\"].dt.year.shift(time=-1))\n",
    "        mask = (\n",
    "            (ds[\"year\"] >= year_start)\n",
    "            & (ds[\"year\"] <= year_stop)\n",
    "            & (ds[\"time\"].dt.season == timeseries)\n",
    "        )\n",
    "    ds = ds.where(mask.compute(), drop=True)\n",
    "\n",
    "    if var_names := set(ds.data_vars) & {\"mtpr\", \"pr\"}:\n",
    "        field = \"precipitation\"\n",
    "    elif var_names := set(ds.data_vars) & {\"tas\", \"t2m\"}:\n",
    "        field = \"temperature\"\n",
    "    else:\n",
    "        raise ValueError(\"Unable to find precipitation or temperature variable.\")\n",
    "    (var_name,) = var_names\n",
    "    da = ds[var_name].rename(field)\n",
    "\n",
    "    # Create timeseries\n",
    "    if timeseries == \"annual\":\n",
    "        da = diagnostics.annual_weighted_mean(da)\n",
    "    else:\n",
    "        da[\"year\"] = da[\"year\"].astype(int)\n",
    "        da = (\n",
    "            da.groupby(\"year\")\n",
    "            .map(diagnostics.seasonal_weighted_mean)\n",
    "            .sel(season=timeseries)\n",
    "        )\n",
    "\n",
    "    # Convert units\n",
    "    with xr.set_options(keep_attrs=True):\n",
    "        if da.name == \"precipitation\":\n",
    "            da *= 3600 * 24\n",
    "            da.attrs[\"units\"] = \"mm/day\"\n",
    "        elif da.name == \"temperature\":\n",
    "            da -= 273.15\n",
    "            da.attrs[\"units\"] = \"Â°C\"\n",
    "            da = da.assign_coords(height=ds[\"height\"] if \"height\" in ds else None)\n",
    "        else:\n",
    "            raise ValueError\n",
    "    return da\n",
    "\n",
    "\n",
    "def compute_climatology(da, clima_year_start, clima_year_stop):\n",
    "    return da.sel(year=slice(clima_year_start, clima_year_stop)).mean(\n",
    "        \"year\", keep_attrs=True\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_anomaly(da, clima_year_start, clima_year_stop):\n",
    "    clima = compute_climatology(da, clima_year_start, clima_year_stop)\n",
    "    anoma = da - clima\n",
    "    units = da.attrs[\"units\"]\n",
    "    if da.name == \"precipitation\":\n",
    "        anoma *= 100 / da\n",
    "        units = \"%\"\n",
    "    anoma.attrs.update({\"long_name\": f\"{da.name} anomaly\", \"units\": units})\n",
    "    return anoma\n",
    "\n",
    "\n",
    "def spatial_weighted_trends(\n",
    "    obj,\n",
    "    year_start,\n",
    "    year_stop,\n",
    "    clima_year_start,\n",
    "    clima_year_stop,\n",
    "    timeseries,\n",
    "    weights,\n",
    "    lon_slice,\n",
    "    lat_slice,\n",
    "    request_lsm,\n",
    "):\n",
    "    if isinstance(obj, xr.DataArray):\n",
    "        da = obj\n",
    "    else:\n",
    "        ds = utils.regionalise(obj, lon_slice=lon_slice, lat_slice=lat_slice)\n",
    "        if request_lsm:\n",
    "            ds_lsm = download.download_and_transform(*request_lsm)\n",
    "            da_lsm = ds_lsm[\"lsm\"].squeeze(\"time\", drop=True)\n",
    "            da_lsm = diagnostics.regrid(da_lsm, ds, method=\"nearest_s2d\")\n",
    "            ds = ds.where(da_lsm > 0.5)\n",
    "\n",
    "        da = diagnostics.spatial_weighted_mean(\n",
    "            get_timeseries(ds, year_start, year_stop, timeseries), weights=weights\n",
    "        )\n",
    "    anoma = compute_anomaly(da, clima_year_start, clima_year_stop)\n",
    "\n",
    "    # Compute anomaly trends\n",
    "    ds = (\n",
    "        original_test(\n",
    "            anoma.expand_dims(\"x\"),\n",
    "            coords_name={\"time\": \"year\", \"x\": \"x\"},\n",
    "        )\n",
    "        .compute()\n",
    "        .squeeze(\"x\", drop=True)\n",
    "    )\n",
    "\n",
    "    # Add variable and anomaly\n",
    "    return ds.merge({da.name: da, f\"{da.name}_anomaly\": anoma})\n",
    "\n",
    "\n",
    "def regridded_trends(\n",
    "    ds,\n",
    "    year_start,\n",
    "    year_stop,\n",
    "    clima_year_start,\n",
    "    clima_year_stop,\n",
    "    timeseries,\n",
    "    grid_out=None,\n",
    "    **kwargs,\n",
    "):\n",
    "    da = get_timeseries(ds, year_start, year_stop, timeseries)\n",
    "\n",
    "    # Compute anomaly trends\n",
    "    coords_name = {\"time\": \"year\"} | {\n",
    "        k: v for k, v in zip((\"x\", \"y\"), ds[[\"longitude\", \"latitude\"]].dims)\n",
    "    }\n",
    "    ds_trend = original_test(da, coords_name=coords_name).compute()\n",
    "    ds_trend = ds_trend.rename({k: v for k, v in coords_name.items() if k != \"time\"})\n",
    "    ds_trend = ds_trend.assign_coords(ds.drop_dims(\"time\").coords)\n",
    "\n",
    "    # Add variable and climatology\n",
    "    clima = compute_climatology(da, clima_year_start, clima_year_stop)\n",
    "    ds_trend[f\"{da.name}_climatology\"] = clima\n",
    "    if grid_out is not None:\n",
    "        ds_trend = ds_trend.cf.add_bounds(\n",
    "            coord\n",
    "            for coord in (\"longitude\", \"latitude\")\n",
    "            if coord not in ds_trend.cf.bounds\n",
    "        )\n",
    "        ds_trend = diagnostics.regrid(ds_trend, grid_out, **kwargs)\n",
    "    return ds_trend"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute spatial weighted trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "transform_func_kwargs = {\n",
    "    \"year_start\": year_start,\n",
    "    \"year_stop\": year_stop,\n",
    "    \"clima_year_start\": clima_year_start,\n",
    "    \"clima_year_stop\": clima_year_stop,\n",
    "    \"lon_slice\": lon_slice,\n",
    "    \"lat_slice\": lat_slice,\n",
    "    \"timeseries\": timeseries,\n",
    "    \"request_lsm\": request_lsm if mask_sea else None,\n",
    "}\n",
    "for model in models + [\"ERA5\"]:\n",
    "    print(f\"Downloading and processing {model}\")\n",
    "    if model == \"ERA5\":\n",
    "        request_model = request_era\n",
    "    else:\n",
    "        request_model = request_sim\n",
    "        for request in request_model[1]:\n",
    "            request[model_key] = model\n",
    "    ds = download.download_and_transform(\n",
    "        *request_model,\n",
    "        chunks=chunks if model == \"ERA5\" else {},\n",
    "        transform_func=spatial_weighted_trends,\n",
    "        transform_func_kwargs={\n",
    "            \"weights\": True if model == \"ERA5\" else weights,\n",
    "            **transform_func_kwargs,\n",
    "        },\n",
    "        transform_chunks=False,\n",
    "    )\n",
    "    datasets.append(ds.expand_dims(model=[model]))\n",
    "\n",
    "# Combine and add ensemble\n",
    "ds_mean_trend = xr.concat(datasets, \"model\")\n",
    "da_ensemble = (\n",
    "    ds_mean_trend[variable].drop_sel(model=\"ERA5\").mean(\"model\", keep_attrs=True)\n",
    ")\n",
    "ds_ensemble_trend = spatial_weighted_trends(\n",
    "    da_ensemble, weights=weights, **transform_func_kwargs\n",
    ")\n",
    "ds_mean_trend = ds_mean_trend.merge(\n",
    "    ds_ensemble_trend.expand_dims(model=[collection_id])\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot field and anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in [variable, f\"{variable}_anomaly\"]:\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    da = ds_mean_trend[var]\n",
    "    colored_models = [collection_id, \"ERA5\"]\n",
    "    da_colored = ds_mean_trend[var].sel(model=colored_models)\n",
    "    da_grey = ds_mean_trend[var].drop_sel(model=colored_models)\n",
    "    da_colored.plot(hue=\"model\", ax=ax, add_legend=False)\n",
    "    da_grey.plot(hue=\"model\", linewidth=0.5, color=\"grey\", ax=ax, add_legend=False)\n",
    "    ax.set_title(timeseries.upper())\n",
    "    ax.grid()\n",
    "    ax.legend(colored_models + [\"models\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trends boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slope = (ds_mean_trend[\"trend\"] * 10).to_dataframe()[[\"trend\"]]\n",
    "ax = df_slope[df_slope.index != \"ERA5\"].boxplot()\n",
    "\n",
    "df_slope_grey = df_slope[~df_slope.index.isin(colored_models)]\n",
    "ax.scatter(\n",
    "    x=[1] * len(df_slope_grey),\n",
    "    y=df_slope_grey,\n",
    "    color=\"grey\",\n",
    "    marker=\".\",\n",
    "    label=\"models\",\n",
    ")\n",
    "for x, model in enumerate(colored_models):\n",
    "    ax.scatter(x=x + 1, y=df_slope[df_slope.index == model], label=model, marker=\"o\")\n",
    "units = ds_mean_trend[f\"{variable}_anomaly\"].attrs[\"units\"] + \" / decade\"\n",
    "ax.set_ylabel(units)\n",
    "ax.set_title(timeseries.upper())\n",
    "ax.set_xticks(range(1, len(colored_models) + 1), colored_models)\n",
    "_ = ax.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute trend maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloading and processing ERA5\")\n",
    "transform_func_kwargs = {\n",
    "    \"year_start\": year_start,\n",
    "    \"year_stop\": year_stop,\n",
    "    \"clima_year_start\": clima_year_start,\n",
    "    \"clima_year_stop\": clima_year_stop,\n",
    "    \"timeseries\": timeseries,\n",
    "    \"method\": \"conservative\",\n",
    "}\n",
    "\n",
    "ds_era = download.download_and_transform(\n",
    "    *request_era,\n",
    "    chunks=chunks,\n",
    "    transform_func=regridded_trends,\n",
    "    transform_func_kwargs={\"model\": \"ERA5\", **transform_func_kwargs},\n",
    "    transform_chunks=False,\n",
    ")\n",
    "\n",
    "datasets = []\n",
    "for model in models:\n",
    "    print(f\"Downloading and processing {model}\")\n",
    "    request_model = request_sim\n",
    "    for request in request_model[1]:\n",
    "        request[model_key] = model\n",
    "    ds = download.download_and_transform(\n",
    "        *request_model,\n",
    "        transform_func=regridded_trends,\n",
    "        transform_func_kwargs={\n",
    "            \"grid_out\": ds_era[[\"longitude\", \"latitude\"]],\n",
    "            \"periodic\": periodic,\n",
    "            **transform_func_kwargs,\n",
    "        },\n",
    "        transform_chunks=False,\n",
    "    )\n",
    "    # Cache global trends, then regionalise\n",
    "    ds = utils.regionalise(ds, lon_slice=lon_slice, lat_slice=lat_slice)\n",
    "    datasets.append(ds.expand_dims(model=[model]))\n",
    "\n",
    "\n",
    "# Regionalise ERA5\n",
    "ds_era = utils.regionalise(\n",
    "    ds_era, lon_slice=lon_slice, lat_slice=lat_slice\n",
    ").expand_dims(model=[\"ERA5\"])\n",
    "\n",
    "# Concatenate\n",
    "ds_sim_regr = xr.concat(datasets, \"model\")\n",
    "if mask_sea:\n",
    "    ds_lsm = download.download_and_transform(\n",
    "        *request_lsm,\n",
    "        transform_func=utils.regionalise,\n",
    "        transform_func_kwargs={\"lon_slice\": lon_slice, \"lat_slice\": lat_slice},\n",
    "    )\n",
    "    da_lsm = ds_lsm[\"lsm\"].squeeze(\"time\", drop=True)\n",
    "    ds_era = ds_era.where(da_lsm > 0.5)\n",
    "    ds_sim_regr = ds_sim_regr.where(da_lsm > 0.5)\n",
    "\n",
    "# Add ensem\n",
    "ds_ens = ds_sim_regr.mean(\"model\").expand_dims(model=[collection_id])\n",
    "ds_all_regr = xr.concat([ds_era, ds_ens, ds_sim_regr], \"model\")\n",
    "\n",
    "# Compute anomaly trends\n",
    "da_trend = ds_all_regr[\"trend\"] * 10\n",
    "units = ds_all_regr[f\"{variable}_climatology\"].attrs[\"units\"] + \"/decade\"\n",
    "if variable == \"precipitation\":\n",
    "    da_trend *= 100 / ds_all_regr[f\"{variable}_climatology\"]\n",
    "    units = \"%/decade\"\n",
    "da_trend.name = \"\"\n",
    "da_trend.attrs.update({\"units\": units})\n",
    "\n",
    "# Compute bias\n",
    "da_bias = (ds_all_regr[\"trend\"].drop_sel(model=\"ERA5\") - ds_era[\"trend\"].squeeze()) * 10\n",
    "units = ds_all_regr[f\"{variable}_climatology\"].attrs[\"units\"] + \"/decade\"\n",
    "if variable == \"precipitation\":\n",
    "    da_bias *= 100 / ds_era[f\"{variable}_climatology\"].squeeze()\n",
    "    units = \"%/decade\"\n",
    "da_bias.name = \"\"\n",
    "da_bias.attrs.update({\"units\": units})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define plotting kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Projection = (\n",
    "    ccrs.Robinson\n",
    "    if abs(lon_slice.stop - lon_slice.start) >= 360\n",
    "    and abs(lat_slice.stop - lat_slice.start) >= 180\n",
    "    else ccrs.PlateCarree\n",
    ")\n",
    "projection = Projection(central_longitude=(lon_slice.stop + lon_slice.start) / 2)\n",
    "\n",
    "plot_kwargs = {\"levels\": 11, \"robust\": True, \"extend\": \"both\"}\n",
    "trend_kwargs = xr.plot.utils._determine_cmap_params(\n",
    "    da_trend.values,\n",
    "    cmap=\"PuOr\" if variable == \"precipitation\" else \"PuOr_r\",\n",
    "    **plot_kwargs,\n",
    ") | {\"projection\": projection}\n",
    "bias_kwargs = xr.plot.utils._determine_cmap_params(\n",
    "    da_bias.values,\n",
    "    cmap=\"bwr_r\" if variable == \"precipitation\" else \"bwr\",\n",
    "    **plot_kwargs,\n",
    ") | {\"projection\": projection}\n",
    "\n",
    "cbar_ax = [0.05, -0.04, 0.95, 0.04]\n",
    "\n",
    "hatches = [\"\", \"/\" * 5]\n",
    "hatches_kwargs = {\n",
    "    \"plot_func\": \"contourf\",\n",
    "    \"show_stats\": False,\n",
    "    \"cmap\": \"none\",\n",
    "    \"add_colorbar\": False,\n",
    "}\n",
    "p_hatches_kwargs = hatches_kwargs | {\n",
    "    \"levels\": [0, 0.05, 1],\n",
    "    \"hatches\": [\"\", \"/\" * 5],\n",
    "}\n",
    "is_signif_ratio_hatches_kwargs = hatches_kwargs | {\n",
    "    \"levels\": [1, 0.8, 0],\n",
    "    \"hatches\": [\"\", \"/\" * 5][:: 1 if variable == \"precipitation\" else -1],\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ERA5 trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.projected_map(da_trend.sel(model=\"ERA5\"), **trend_kwargs)\n",
    "plot.projected_map(\n",
    "    ds_all_regr[\"p\"].sel(model=\"ERA5\").drop_vars([\"height\", \"season\"], errors=\"ignore\"),\n",
    "    **p_hatches_kwargs,\n",
    ")\n",
    "_ = plt.suptitle(\n",
    "    f\"{variable.title()} trend ({year_start}-{year_stop}) - {timeseries.upper()}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plote esemble trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_signif = xr.where(\n",
    "    ds_sim_regr[\"p\"] <= 0.05,\n",
    "    ds_sim_regr[\"trend\"] / ds_ens[\"trend\"].squeeze() > 0,\n",
    "    False,\n",
    "    keep_attrs=True,\n",
    ")\n",
    "is_signif_ratio = is_signif.sum(\"model\") / is_signif.sizes[\"model\"]\n",
    "is_signif_ratio = is_signif_ratio.where(ds_ens[\"trend\"].notnull())\n",
    "plot.projected_map(\n",
    "    da_trend.sel(model=collection_id).drop_vars([\"height\", \"season\"], errors=\"ignore\"),\n",
    "    stats_weights=weights,\n",
    "    **trend_kwargs,\n",
    ")\n",
    "plot.projected_map(\n",
    "    is_signif_ratio.drop_vars([\"height\", \"season\"], errors=\"ignore\").squeeze(),\n",
    "    **is_signif_ratio_hatches_kwargs,\n",
    ")\n",
    "_ = plt.suptitle(\n",
    "    f\"{variable.title()} trend ({year_start}-{year_stop}) - {timeseries.upper()}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot trends for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = plot.projected_map(\n",
    "    da_trend.drop_sel(model=[\"ERA5\", collection_id]),\n",
    "    col=\"model\",\n",
    "    col_wrap=3,\n",
    "    add_colorbar=False,\n",
    "    **trend_kwargs,\n",
    ")\n",
    "for ax, sel in zip(facet.axs.flatten(), facet.name_dicts.flatten()):\n",
    "    if not sel:\n",
    "        continue\n",
    "    plot.projected_map(\n",
    "        ds_all_regr[\"p\"].sel(**sel).drop_vars([\"height\", \"season\"], errors=\"ignore\"),\n",
    "        ax=ax,\n",
    "        **p_hatches_kwargs,\n",
    "    )\n",
    "    ax.set_extent((lon_slice.start, lon_slice.stop, lat_slice.start, lat_slice.stop))\n",
    "plt.suptitle(\n",
    "    f\"{variable.title()} trend ({year_start}-{year_stop}) - {timeseries.upper()}\"\n",
    ")\n",
    "cax = plt.axes(cbar_ax)\n",
    "_ = plt.colorbar(\n",
    "    facet.axs[0][0].collections[0],\n",
    "    cax=cax,\n",
    "    orientation=\"horizontal\",\n",
    "    label=xr.plot.utils.label_from_attrs(da_trend),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot trend bias for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = plot.projected_map(\n",
    "    da_bias.drop_sel(model=collection_id).drop_vars(\n",
    "        [\"height\", \"season\"], errors=\"ignore\"\n",
    "    ),\n",
    "    col=\"model\",\n",
    "    col_wrap=3,\n",
    "    add_colorbar=False,\n",
    "    **bias_kwargs,\n",
    ")\n",
    "for ax in facet.axs.flatten():\n",
    "    ax.set_extent((lon_slice.start, lon_slice.stop, lat_slice.start, lat_slice.stop))\n",
    "plt.suptitle(\n",
    "    f\"{variable.title()} trend bias ({year_start}-{year_stop}) - {timeseries.upper()}\"\n",
    ")\n",
    "cax = plt.axes(cbar_ax)\n",
    "_ = plt.colorbar(\n",
    "    facet.axs[0][0].collections[0],\n",
    "    cax=cax,\n",
    "    orientation=\"horizontal\",\n",
    "    label=xr.plot.utils.label_from_attrs(da_bias),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot trend bias for ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.projected_map(\n",
    "    da_bias.sel(model=collection_id).drop_vars([\"height\", \"season\"], errors=\"ignore\"),\n",
    "    stats_weights=weights,\n",
    "    **bias_kwargs,\n",
    ")\n",
    "_ = plt.suptitle(\n",
    "    f\"{variable.title()} trend bias ({year_start}-{year_stop}) - {timeseries.upper()}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_trend = da_trend.to_dataset(name=\"trend\")\n",
    "df_stats = xr.concat(\n",
    "    [\n",
    "        diagnostics.spatial_weighted_statistics(\n",
    "            ds_trend.drop_sel(model=\"ERA5\"), weights=weights\n",
    "        ),\n",
    "        diagnostics.spatial_weighted_statistics(\n",
    "            ds_trend.sel(model=\"ERA5\"), weights=True\n",
    "        ),\n",
    "    ],\n",
    "    \"model\",\n",
    ")[\"trend\"].to_pandas()\n",
    "\n",
    "df_error = diagnostics.spatial_weighted_errors(\n",
    "    ds_trend.drop_sel(model=\"ERA5\"), ds_trend.sel(model=\"ERA5\"), weights=weights\n",
    ")[\"trend\"].to_pandas()\n",
    "df_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taylor Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_and_error = pd.concat([df_stats, df_error])\n",
    "tickRMS = np.linspace(0, df_stats_and_error.loc[\"crmse\"].max(), 5, dtype=int)\n",
    "tickSTD = np.linspace(0, df_stats_and_error.loc[\"std\"].max(), 5, dtype=int)\n",
    "skill_metrics.taylor_diagram(\n",
    "    df_stats_and_error.loc[\"std\"].values,\n",
    "    df_stats_and_error.loc[\"crmse\"].values,\n",
    "    df_stats_and_error.loc[\"corr\"].values,\n",
    "    alpha=0.0,\n",
    "    colCOR=\"k\",\n",
    "    colOBS=\"k\",\n",
    "    colRMS=\"m\",\n",
    "    colSTD=\"b\",\n",
    "    markerColor=\"r\" if len(df_stats_and_error.columns) >= 9 else None,  # TODO\n",
    "    markerLabel=list(df_stats_and_error.columns),\n",
    "    markerLegend=\"on\",\n",
    "    markerSize=10,\n",
    "    markerobs=\"o\",\n",
    "    styleCOR=\"--\",\n",
    "    styleOBS=\"--\",\n",
    "    styleRMS=\":\",\n",
    "    styleSTD=\"-.\",\n",
    "    tickRMS=tickRMS,\n",
    "    tickSTD=tickSTD,\n",
    "    titleCOR=\"on\",\n",
    "    titleOBS=\"ERA5\",\n",
    "    titleRMS=\"on\",\n",
    "    titleRMSDangle=40.0,\n",
    "    titleSTD=\"on\",\n",
    "    widthCOR=0.5,\n",
    "    widthOBS=2,\n",
    "    widthRMS=2,\n",
    "    widthSTD=1.0,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
